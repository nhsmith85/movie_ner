{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIT Movie - 3b - Transformer models.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zsRaKLrZQ7wP"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "89235f14b7b446d2b3add5ee0e94df43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_11932fecbd9a40aaa1f4faa963405169",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b3b0a278b8c04db8a181575ff18ac41e",
              "IPY_MODEL_f092514d846a46b89dedb835adc713fd"
            ]
          }
        },
        "11932fecbd9a40aaa1f4faa963405169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3b0a278b8c04db8a181575ff18ac41e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_09976b63680f41628a19d44061c3d36e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c16086d2593421a9aeb1037799dee3d"
          }
        },
        "f092514d846a46b89dedb835adc713fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a23966f9fd6b41a880bb01f5fba1af13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:02&lt;00:00, 154B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_108a5099d73a4510b5e0664f523244b4"
          }
        },
        "09976b63680f41628a19d44061c3d36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c16086d2593421a9aeb1037799dee3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a23966f9fd6b41a880bb01f5fba1af13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "108a5099d73a4510b5e0664f523244b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f614e8f614464d9ab3461ad35208effe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5197ca56684744c7a9fd75d9ded20ee3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_89b9229957624d6481eb51c0bcec1bee",
              "IPY_MODEL_d69311431ea24bd1bcf39af5347a295e"
            ]
          }
        },
        "5197ca56684744c7a9fd75d9ded20ee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89b9229957624d6481eb51c0bcec1bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_746e84e22f7e441fa96ddf2404ad7167",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22ed53344fa541e7a4dc4f4d06d3b202"
          }
        },
        "d69311431ea24bd1bcf39af5347a295e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f69409a4a7064e11ae5e37451639b97e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:02&lt;00:00, 112kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c76ed4c7ed94c06a1ebc438cffee21f"
          }
        },
        "746e84e22f7e441fa96ddf2404ad7167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22ed53344fa541e7a4dc4f4d06d3b202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f69409a4a7064e11ae5e37451639b97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c76ed4c7ed94c06a1ebc438cffee21f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a8e22a7e4c74bf1bfb6a14a91fefd12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_48583eeffd664122b89bdb630147298c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_609b59f31a374600b539f4a3a87ad9ed",
              "IPY_MODEL_360a0b77a3b7442aad9a91990ae3a0c7"
            ]
          }
        },
        "48583eeffd664122b89bdb630147298c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "609b59f31a374600b539f4a3a87ad9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f4238953aead4f4896bf2222abb8cfe2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9399f9ddc024a0992411319c570654b"
          }
        },
        "360a0b77a3b7442aad9a91990ae3a0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a31843bab4814f80866b7a823d81183a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 554kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93cb0af4875344a4b2fee8c9d5caf760"
          }
        },
        "f4238953aead4f4896bf2222abb8cfe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9399f9ddc024a0992411319c570654b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a31843bab4814f80866b7a823d81183a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93cb0af4875344a4b2fee8c9d5caf760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c0f791942ae424a89f884a04a423f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_155b5f5e3fa84780b3d5b1731796f0cd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bb6dda07753c4003a09f23de37d28d8d",
              "IPY_MODEL_42f45c67116e44df8d89e34b233518c3"
            ]
          }
        },
        "155b5f5e3fa84780b3d5b1731796f0cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb6dda07753c4003a09f23de37d28d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c73c0b02be0c4831a8b0e6e957d20ee8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d484931186ac4576b8b319a332b45367"
          }
        },
        "42f45c67116e44df8d89e34b233518c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0a223addcd743c291014c2881222c20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:23&lt;00:00, 11.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b90b56d49b94a6dae9231478040f797"
          }
        },
        "c73c0b02be0c4831a8b0e6e957d20ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d484931186ac4576b8b319a332b45367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0a223addcd743c291014c2881222c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b90b56d49b94a6dae9231478040f797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1cc38313b6d462f9464f91c178bbb52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_550d64db05b8439abb69dc8f1426a4be",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d409c00d91d14545afee4bf2922c57bc",
              "IPY_MODEL_13271d762bc142d4bcca58fee9d1853c"
            ]
          }
        },
        "550d64db05b8439abb69dc8f1426a4be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d409c00d91d14545afee4bf2922c57bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b2cb215b84b6490d8237359fbc7a3f4c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3273dfa81f3485fab1b609fa0e30160"
          }
        },
        "13271d762bc142d4bcca58fee9d1853c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2fd24205c95e4a0e8c7428e133328271",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 317kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6887af4f6354162afe7c3a076e35e55"
          }
        },
        "b2cb215b84b6490d8237359fbc7a3f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3273dfa81f3485fab1b609fa0e30160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2fd24205c95e4a0e8c7428e133328271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6887af4f6354162afe7c3a076e35e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28aa0edec8ae4441922251d9c2437c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a19b984715774fd2b4c3736cc5c7dab2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4a71e1a5f6dc4b75a7da11b4a1e7afcd",
              "IPY_MODEL_1a365a1043a3401a9ae6d791bad80f01"
            ]
          }
        },
        "a19b984715774fd2b4c3736cc5c7dab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a71e1a5f6dc4b75a7da11b4a1e7afcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b50dff8c05694a4e8fcc4a2b01254aa4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8eec1bf1733447cf8fa78b25d4bc9adf"
          }
        },
        "1a365a1043a3401a9ae6d791bad80f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8830ff252340472aa3468d0d7abeb1ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 557kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29139f2bbf8a4868a89ada4f0d2ccf80"
          }
        },
        "b50dff8c05694a4e8fcc4a2b01254aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8eec1bf1733447cf8fa78b25d4bc9adf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8830ff252340472aa3468d0d7abeb1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29139f2bbf8a4868a89ada4f0d2ccf80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88281e681de446a99d3fadfb323c49f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dc884e441d8c42419863897f6f228862",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3826d7a37acf4b2fbf6f355275534779",
              "IPY_MODEL_da96d13b08dd4130a7362a54a36d4dc9"
            ]
          }
        },
        "dc884e441d8c42419863897f6f228862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3826d7a37acf4b2fbf6f355275534779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_36f4492397134ad081c9004531553c50",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 434,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 434,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a17721e8df9c4c92a0f42fcc8ab417ca"
          }
        },
        "da96d13b08dd4130a7362a54a36d4dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8ae9193b81ab48e38ce73f7750d749f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 434/434 [00:00&lt;00:00, 909B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_455466604bfd46e38a5b3263fcdc49d4"
          }
        },
        "36f4492397134ad081c9004531553c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a17721e8df9c4c92a0f42fcc8ab417ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ae9193b81ab48e38ce73f7750d749f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "455466604bfd46e38a5b3263fcdc49d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca8b072dd3744da1b3ffaaa3240d7fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f53fc2bb69b84cf6ad1c0866fa48c624",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b4eaa799e8c741a6b488927771459124",
              "IPY_MODEL_6681137b579548e59fb8103cbd5fa9ec"
            ]
          }
        },
        "f53fc2bb69b84cf6ad1c0866fa48c624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4eaa799e8c741a6b488927771459124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d208c7d93ebe4f6394f0bbcb0412ac94",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1344997306,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1344997306,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10629d6a08f54e23b7dbf17e8f159024"
          }
        },
        "6681137b579548e59fb8103cbd5fa9ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dfeafa3f1d114aa08238cce8b3184475",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.34G/1.34G [00:19&lt;00:00, 68.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c12d99461083489a9597f59726d1b5d8"
          }
        },
        "d208c7d93ebe4f6394f0bbcb0412ac94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10629d6a08f54e23b7dbf17e8f159024": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dfeafa3f1d114aa08238cce8b3184475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c12d99461083489a9597f59726d1b5d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75b46960b609431386927f9b62dd9e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_579f4167af7240c0bfd5f973d34858ae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_37c4e4e5a03f41df9d91c249c40786ae",
              "IPY_MODEL_39038a4a11a2405d9273f1308c0da2ac"
            ]
          }
        },
        "579f4167af7240c0bfd5f973d34858ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37c4e4e5a03f41df9d91c249c40786ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_639c567cfb844954bcf778052b8e2edf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76f093e5506f436f8b1c9b105088539f"
          }
        },
        "39038a4a11a2405d9273f1308c0da2ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_922b7c7071574f66941cfe864fcfa699",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:01&lt;00:00, 673kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69bac9665511422a97a834084a531205"
          }
        },
        "639c567cfb844954bcf778052b8e2edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76f093e5506f436f8b1c9b105088539f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "922b7c7071574f66941cfe864fcfa699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69bac9665511422a97a834084a531205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b46e145ab8114505ba37a281a6b9deb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_54a44ccdd4824708922466888375360a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5171c9f82f7546bf9586bde775a37053",
              "IPY_MODEL_c551399998b246a9a35888ebf3a6568d"
            ]
          }
        },
        "54a44ccdd4824708922466888375360a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5171c9f82f7546bf9586bde775a37053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c6c143339b334486a80b0982070ca10e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed83b42b39604eb597bcf81553e24c03"
          }
        },
        "c551399998b246a9a35888ebf3a6568d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3ada8ab0bb53498d8fb726f8148e758b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:02&lt;00:00, 208kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3973f58b5734aaf876fd242c9a5f88b"
          }
        },
        "c6c143339b334486a80b0982070ca10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed83b42b39604eb597bcf81553e24c03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ada8ab0bb53498d8fb726f8148e758b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3973f58b5734aaf876fd242c9a5f88b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d892f57fae54fa48b5e8f35fd2ae3b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_69d57893af4d4004844f9e4c7d93a8d9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5a8fb41adf534f72b97cd68e09f8b5ce",
              "IPY_MODEL_54a3627948c84769ab1f5dc6c0ea188b"
            ]
          }
        },
        "69d57893af4d4004844f9e4c7d93a8d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a8fb41adf534f72b97cd68e09f8b5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e57a0c5655444f90927635e19577e0f2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355863,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355863,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d28b4c57b7c4105877709d94eb945fa"
          }
        },
        "54a3627948c84769ab1f5dc6c0ea188b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b913ab31526641a0b4fec9ebaad9b07d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.38MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a838ab51697d455294b54a03e6cb5443"
          }
        },
        "e57a0c5655444f90927635e19577e0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d28b4c57b7c4105877709d94eb945fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b913ab31526641a0b4fec9ebaad9b07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a838ab51697d455294b54a03e6cb5443": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "755f879722a442d1b73ad3e090114cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2eab4c0377754dbab90762729b1fb422",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d92527e8f9454455a7110307ab3e747d",
              "IPY_MODEL_4cfc099451284c44a357bd5bd7aa4c9e"
            ]
          }
        },
        "2eab4c0377754dbab90762729b1fb422": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d92527e8f9454455a7110307ab3e747d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2359cb61d5e2464aa3254f89f7e2f27b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 482,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 482,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3954fbcb10e44cbb28ef3635dbc9bbb"
          }
        },
        "4cfc099451284c44a357bd5bd7aa4c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e08db1198d5472db61868f844c6c23d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 482/482 [00:00&lt;00:00, 3.39kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_249f7b203e91495999cd80a0c06bfea2"
          }
        },
        "2359cb61d5e2464aa3254f89f7e2f27b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3954fbcb10e44cbb28ef3635dbc9bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e08db1198d5472db61868f844c6c23d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "249f7b203e91495999cd80a0c06bfea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb7c60d0eb164ef5a794462534d13074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2a566bb724f1463a93402e778e040720",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d8184c11ab6d4652a346e383447b1ea0",
              "IPY_MODEL_ce0c20dc37fa4cdcbb1f22fb3d3c30d9"
            ]
          }
        },
        "2a566bb724f1463a93402e778e040720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8184c11ab6d4652a346e383447b1ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3670e0c83a2241eaa7dff489cffd5d5f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1425941629,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1425941629,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95a3d10f094b4d21a0962f587cd5910f"
          }
        },
        "ce0c20dc37fa4cdcbb1f22fb3d3c30d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aab406c2738d41a5ae67b3a1a8783657",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.43G/1.43G [00:23&lt;00:00, 60.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee5927d519e64597b0a6dcd148944c0d"
          }
        },
        "3670e0c83a2241eaa7dff489cffd5d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95a3d10f094b4d21a0962f587cd5910f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aab406c2738d41a5ae67b3a1a8783657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee5927d519e64597b0a6dcd148944c0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06OQKN0T59bd"
      },
      "source": [
        "# MIT Movie Dataset - Transformer Models\n",
        "\n",
        "This notebook contains the data preparation and model development code for fine-tuning Transformer models for our NER task.\n",
        "\n",
        "https://huggingface.co/transformers/pretrained_models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_FKvy6O56zK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341c4672-05b2-441d-d62a-8265729aaeab"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xnaOpm66evY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2f1c9737-32ac-4726-924a-2e4c4f9f1258"
      },
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/DAAN888/data')\n",
        "#os.chdir('/content/drive/My Drive/DAAN888/data')\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/DAAN888/data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBk2FvdZ6kaL"
      },
      "source": [
        "model_dir = '/content/drive/My Drive/Colab Notebooks/DAAN888/models/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x15kBwH6n2k"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Colab Notebooks/DAAN888/data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9eIgn0O7Rov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4433c9a-ac23-4f25-8f75-e1e5e6260648"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Nov 21 12:51:34 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    24W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpFOjZxX67Zy"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpF_iemN8M01"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMVdD22r8PgJ"
      },
      "source": [
        "import pickle \n",
        "\n",
        "with open('mitmovie.pickle', 'rb') as handle:\n",
        "    dataset = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yLepx_H9Hau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80ce024-c93e-44fc-9b62-fdf225062dd6"
      },
      "source": [
        "# first row in train set\n",
        "list(zip(dataset['train_tokens'][0], dataset['train_labels'][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('what', 'O'),\n",
              " ('movies', 'O'),\n",
              " ('star', 'O'),\n",
              " ('bruce', 'B-ACTOR'),\n",
              " ('willis', 'I-ACTOR')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTjq41hi9StY"
      },
      "source": [
        "## DistilBert Model\n",
        "\n",
        "Documentation for this model can be found: \n",
        "https://huggingface.co/transformers/model_doc/distilbert.html\n",
        "\n",
        "More model details here: https://github.com/huggingface/transformers/tree/master/examples/distillation\n",
        "\n",
        "Following HuggingFace distilbert tutorial: https://huggingface.co/transformers/custom_datasets.html#tok-ner\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLp5lbTQucac"
      },
      "source": [
        "model_name = 'distilbert-base-uncased'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n11D7BV166lJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e735cf-0aa3-485a-bc3e-e32382bfcf23"
      },
      "source": [
        "!pip install transformers==3.5.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/34/fb092588df61bf33f113ade030d1cbe74fb73a0353648f8dd938a223dce7/transformers-3.5.0-py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 27.4MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 23.5MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 18.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 15.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 17.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 16.7MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 13.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92kB 14.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102kB 14.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112kB 14.2MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 14.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 133kB 14.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143kB 14.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153kB 14.2MB/s eta 0:00:01\r\u001b[K     |████                            | 163kB 14.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 174kB 14.2MB/s eta 0:00:01\r\u001b[K     |████▌                           | 184kB 14.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 204kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 215kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 225kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 235kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 245kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 256kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 266kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 276kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 286kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 296kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 307kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 317kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 327kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 337kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 348kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 358kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 368kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 378kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 389kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 399kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 409kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 419kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 430kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 440kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 450kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 460kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 471kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 481kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 491kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 501kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 512kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 522kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 532kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 542kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 552kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 563kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 573kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 583kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 593kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 604kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 614kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 624kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 634kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 645kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 655kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 665kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 675kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 686kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 696kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 706kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 716kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 727kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 737kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 747kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 757kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 768kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 778kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 788kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 798kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 808kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 819kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 829kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 839kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 849kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 860kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 870kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 880kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 890kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 901kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 911kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 921kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 931kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 942kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 952kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 962kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 972kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 983kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 993kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 14.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (2.23.0)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 44.0MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 61.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (2019.12.20)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (3.12.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 54.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.0) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.5.0) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.5.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.5.0) (50.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.0) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=fb83a2bd7f6beeb859c4b247903cf197b008e55f54b48c7987eba78cef362764\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I7A_mFBIPcM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c8214f1e-9615-46ea-a5ea-66e2acbea5cd"
      },
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46MUK1_NIiL8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f65e809-44cb-4db4-ecee-3c85688eecc9"
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.7.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTXrq-JE-XJN"
      },
      "source": [
        "### Encode Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwMA5_dT-ZAv"
      },
      "source": [
        "# get the set of unique labels in the movie dataset\n",
        "uniq_labels = list(set([label for doc in dataset['train_labels'] for label in doc]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6W4Al0Q-7nQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e65132-974f-41ff-e753-a509fdb5af90"
      },
      "source": [
        "# assign a number to each label\n",
        "label_encoding = {label: id for id, label in enumerate(uniq_labels)}\n",
        "label_encoding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-ACTOR': 24,\n",
              " 'B-CHARACTER': 20,\n",
              " 'B-DIRECTOR': 16,\n",
              " 'B-GENRE': 10,\n",
              " 'B-PLOT': 18,\n",
              " 'B-RATING': 7,\n",
              " 'B-RATINGS_AVERAGE': 6,\n",
              " 'B-REVIEW': 17,\n",
              " 'B-SONG': 4,\n",
              " 'B-TITLE': 2,\n",
              " 'B-TRAILER': 1,\n",
              " 'B-YEAR': 13,\n",
              " 'I-ACTOR': 19,\n",
              " 'I-CHARACTER': 15,\n",
              " 'I-DIRECTOR': 5,\n",
              " 'I-GENRE': 3,\n",
              " 'I-PLOT': 14,\n",
              " 'I-RATING': 12,\n",
              " 'I-RATINGS_AVERAGE': 11,\n",
              " 'I-REVIEW': 0,\n",
              " 'I-SONG': 23,\n",
              " 'I-TITLE': 9,\n",
              " 'I-TRAILER': 21,\n",
              " 'I-YEAR': 8,\n",
              " 'O': 22}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK3wo3ZqAXEI"
      },
      "source": [
        "### Encode Texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWI_TGxFAiVC"
      },
      "source": [
        "To encode the texts, we have to use the same Tokenizer that DistilBert was trained on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ3AauEkAZK_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "89235f14b7b446d2b3add5ee0e94df43",
            "11932fecbd9a40aaa1f4faa963405169",
            "b3b0a278b8c04db8a181575ff18ac41e",
            "f092514d846a46b89dedb835adc713fd",
            "09976b63680f41628a19d44061c3d36e",
            "8c16086d2593421a9aeb1037799dee3d",
            "a23966f9fd6b41a880bb01f5fba1af13",
            "108a5099d73a4510b5e0664f523244b4",
            "f614e8f614464d9ab3461ad35208effe",
            "5197ca56684744c7a9fd75d9ded20ee3",
            "89b9229957624d6481eb51c0bcec1bee",
            "d69311431ea24bd1bcf39af5347a295e",
            "746e84e22f7e441fa96ddf2404ad7167",
            "22ed53344fa541e7a4dc4f4d06d3b202",
            "f69409a4a7064e11ae5e37451639b97e",
            "2c76ed4c7ed94c06a1ebc438cffee21f",
            "5a8e22a7e4c74bf1bfb6a14a91fefd12",
            "48583eeffd664122b89bdb630147298c",
            "609b59f31a374600b539f4a3a87ad9ed",
            "360a0b77a3b7442aad9a91990ae3a0c7",
            "f4238953aead4f4896bf2222abb8cfe2",
            "a9399f9ddc024a0992411319c570654b",
            "a31843bab4814f80866b7a823d81183a",
            "93cb0af4875344a4b2fee8c9d5caf760"
          ]
        },
        "outputId": "80ef0fc5-784b-4ab0-efba-1ca6f70ee508"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89235f14b7b446d2b3add5ee0e94df43",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f614e8f614464d9ab3461ad35208effe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a8e22a7e4c74bf1bfb6a14a91fefd12",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX65Xfn8AOCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "788e4535-92d3-41d6-cf03-d36194fbbc31"
      },
      "source": [
        "print('There are %s words in this tokenizer object' % tokenizer.vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 30522 words in this tokenizer object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG6b_0PlCIs_"
      },
      "source": [
        "# use the tokenizer to encode the texts \n",
        "train_encodings = tokenizer(dataset['train_tokens'], \n",
        "                            is_split_into_words=True, \n",
        "                            return_offsets_mapping=True, \n",
        "                            padding=True, \n",
        "                            truncation=True)\n",
        "\n",
        "test_encodings = tokenizer(dataset['test_tokens'], \n",
        "                           is_split_into_words=True, \n",
        "                           return_offsets_mapping=True, \n",
        "                           padding=True, \n",
        "                           truncation=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z69Y9Og_GQ65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "084833dc-22c2-4986-979b-136e5e8e7b06"
      },
      "source": [
        "train_encodings.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'offset_mapping'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1IgSpEL8Nn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e66ad4cd-77ea-4751-c75c-39bb9b520bcc"
      },
      "source": [
        "# make sure same number of docs\n",
        "len(train_encodings['input_ids']), len(dataset['train_tokens'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9775, 9775)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noh1RtG9SRiz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0040b314-c767-4892-feb4-81d6cb69f236"
      },
      "source": [
        "dataset['train_tokens'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'movies', 'star', 'bruce', 'willis']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKWWquhJTbIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5fa724-6ddb-4d2d-d0dc-331694194fee"
      },
      "source": [
        "# preview what the encoded result looks like\n",
        "list(zip(train_encodings['input_ids'][0][0:12], train_encodings['attention_mask'][0][0:12], train_encodings['offset_mapping'][0][0:12]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(101, 1, (0, 0)),\n",
              " (2054, 1, (0, 4)),\n",
              " (5691, 1, (0, 6)),\n",
              " (2732, 1, (0, 4)),\n",
              " (5503, 1, (0, 5)),\n",
              " (12688, 1, (0, 6)),\n",
              " (102, 1, (0, 0)),\n",
              " (0, 0, (0, 0)),\n",
              " (0, 0, (0, 0)),\n",
              " (0, 0, (0, 0)),\n",
              " (0, 0, (0, 0)),\n",
              " (0, 0, (0, 0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79CSs5q1sT2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "747c1a09-95f6-448b-d76d-c3050c962fe5"
      },
      "source": [
        "# the model expects all docs to be same length (51) \n",
        "# the attention mask will tell the model to ignore the padding with zeros\n",
        "print('Length of sequences is %s ' % len(train_encodings['input_ids'][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of sequences is 51 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyphGlDeG9JH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35804f68-839d-48b5-b0e4-bb5cc3417085"
      },
      "source": [
        "doc = 1\n",
        "\n",
        "# first document in dataset\n",
        "print( dataset['train_tokens'][doc] )\n",
        "\n",
        "print()\n",
        "\n",
        "# check out new tokenization result as words\n",
        "print( tokenizer.convert_ids_to_tokens( train_encodings['input_ids'][doc][0:13]) )\n",
        "\n",
        "# check out new tokenization result as ids\n",
        "print( train_encodings['input_ids'][doc][0:13] )\n",
        "\n",
        "# check out attentions\n",
        "print( train_encodings['attention_mask'][doc][0:13] )\n",
        "\n",
        "# check out offsets\n",
        "print( train_encodings['offset_mapping'][doc][0:13] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['show', 'me', 'films', 'with', 'drew', 'barrymore', 'from', 'the', '1980s']\n",
            "\n",
            "['[CLS]', 'show', 'me', 'films', 'with', 'drew', 'barry', '##more', 'from', 'the', '1980s', '[SEP]', '[PAD]']\n",
            "[101, 2265, 2033, 3152, 2007, 3881, 6287, 5974, 2013, 1996, 3865, 102, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
            "[(0, 0), (0, 4), (0, 2), (0, 5), (0, 4), (0, 4), (0, 5), (5, 9), (0, 4), (0, 3), (0, 5), (0, 0), (0, 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9fpoLJAXNNP"
      },
      "source": [
        "find_subwords = []\n",
        "for i, offset_list in enumerate(train_encodings['offset_mapping']):\n",
        "  for j, offset_tuple in enumerate(offset_list):\n",
        "    if offset_tuple[0] != 0:\n",
        "      find_subwords.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DYHVOAYX-bM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db57cf2-edd1-46c0-d28d-30da8df14b62"
      },
      "source": [
        "np.unique(find_subwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,    2,    3, ..., 9752, 9767, 9772])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEm2Np6AY604",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76aa7de2-41e6-42dc-aa8b-6f487234a239"
      },
      "source": [
        "dataset['train_tokens'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['show', 'me', 'films', 'with', 'drew', 'barrymore', 'from', 'the', '1980s']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxXf1KjXY1dz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3168ed-e604-4d84-dc98-5870c23c8d83"
      },
      "source": [
        "list(zip(train_encodings['input_ids'][1][0:12], train_encodings['attention_mask'][1][0:12], train_encodings['offset_mapping'][1][0:12]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(101, 1, (0, 0)),\n",
              " (2265, 1, (0, 4)),\n",
              " (2033, 1, (0, 2)),\n",
              " (3152, 1, (0, 5)),\n",
              " (2007, 1, (0, 4)),\n",
              " (3881, 1, (0, 4)),\n",
              " (6287, 1, (0, 5)),\n",
              " (5974, 1, (5, 9)),\n",
              " (2013, 1, (0, 4)),\n",
              " (1996, 1, (0, 3)),\n",
              " (3865, 1, (0, 5)),\n",
              " (102, 1, (0, 0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDi5J3t0JiA5"
      },
      "source": [
        "### Adjust Labels for Vocab Offset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHSOdoauJsw2"
      },
      "source": [
        "In the print out above you can see that \"barrymore\" gets transformed into \"barry##\", \"##more\". This is because the name is not in the vocabulary of the model, however, those small subwords \"barry##\" and \"##more\" are. So the offsetting notifies the model of this splitting of the word. However, we have to adjust the labels now to account for this separation. \n",
        "\n",
        "Based on https://datascience.stackexchange.com/questions/69640/what-should-be-the-labels-for-subword-tokens-in-bert-for-ner-task we will not drag the label to the new subword feature because that would introduce more instances of that class and change the number of support instances thus making the models difficult to compare. \n",
        "\n",
        "Also some comments to consider for an alternative strategy: https://github.com/google-research/bert/issues/646\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3xtOvJfGfdC"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def adjust_labels_for_offset(original_labels, label_dictionary, encodings):\n",
        "\n",
        "    # convert to the numeric encoding of the label\n",
        "    labels = [[label_dictionary[label] for label in doc] for doc in original_labels]\n",
        "\n",
        "    encoded_labels = []\n",
        "    for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
        "\n",
        "        # create an empty array of -100\n",
        "        doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
        "        arr_offset = np.array(doc_offset)\n",
        "\n",
        "        # set labels whose first offset position is 0 and the second is not 0\n",
        "        doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
        "        encoded_labels.append(doc_enc_labels.tolist())\n",
        "\n",
        "    return encoded_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYxKLNraLgJl"
      },
      "source": [
        "train_labels = adjust_labels_for_offset(dataset['train_labels'], \n",
        "                                        label_encoding, \n",
        "                                        train_encodings)\n",
        "\n",
        "test_labels = adjust_labels_for_offset(dataset['test_labels'],\n",
        "                                      label_encoding, \n",
        "                                      test_encodings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-vrtcZML9ne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "825360e6-0781-42a9-cde0-e95ae35ce357"
      },
      "source": [
        "id_to_label = {id: label for (label,id) in label_encoding.items()}\n",
        "id_to_label[-100] = 'X'\n",
        "\n",
        "#print( tokenizer.convert_ids_to_tokens(encoding_example) )\n",
        "#print([id_to_label[id] for id in train_labels[0][0:9]])\n",
        "list(zip( tokenizer.convert_ids_to_tokens(train_encodings['input_ids'][0][0:15]), [id_to_label[id] for id in train_labels[0][0:15]], train_labels[0][0:15] )) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('[CLS]', 'X', -100),\n",
              " ('what', 'O', 22),\n",
              " ('movies', 'O', 22),\n",
              " ('star', 'O', 22),\n",
              " ('bruce', 'B-ACTOR', 24),\n",
              " ('willis', 'I-ACTOR', 19),\n",
              " ('[SEP]', 'X', -100),\n",
              " ('[PAD]', 'X', -100),\n",
              " ('[PAD]', 'X', -100),\n",
              " ('[PAD]', 'X', -100),\n",
              " ('[PAD]', 'X', -100),\n",
              " ('[PAD]', 'X', -100),\n",
              " ('[PAD]', 'X', -100),\n",
              " ('[PAD]', 'X', -100),\n",
              " ('[PAD]', 'X', -100)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GILUkgw7kMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a830facc-e2d0-436f-f53c-109957fe104b"
      },
      "source": [
        "len(np.unique(train_labels)), len(uniq_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nr_OfzM-SDV"
      },
      "source": [
        "### Prepare Pytorch Datasets\n",
        "\n",
        "https://huggingface.co/transformers/custom_datasets.html#ft-trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKWqaHC--VQl"
      },
      "source": [
        "import torch\n",
        "\n",
        "# pytorch is expecting a certain type of dataset \n",
        "\n",
        "class pt_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# remove the offset_mapping\n",
        "train_encodings.pop(\"offset_mapping\") \n",
        "test_encodings.pop(\"offset_mapping\")\n",
        "\n",
        "train_dataset = pt_dataset(train_encodings, train_labels)\n",
        "test_dataset = pt_dataset(test_encodings, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLjq3I2SFUxf"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az80WnfiE-sv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175,
          "referenced_widgets": [
            "2c0f791942ae424a89f884a04a423f22",
            "155b5f5e3fa84780b3d5b1731796f0cd",
            "bb6dda07753c4003a09f23de37d28d8d",
            "42f45c67116e44df8d89e34b233518c3",
            "c73c0b02be0c4831a8b0e6e957d20ee8",
            "d484931186ac4576b8b319a332b45367",
            "a0a223addcd743c291014c2881222c20",
            "7b90b56d49b94a6dae9231478040f797"
          ]
        },
        "outputId": "b4886630-a6c5-45de-eed2-8f4bed5d5f07"
      },
      "source": [
        "from transformers import DistilBertForTokenClassification, AutoModelForTokenClassification\n",
        "\n",
        "# load the pretrained model from huggingface\n",
        "#model = DistilBertForTokenClassification.from_pretrained('distilbert-base-cased', num_labels=len(uniq_labels))\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name,\n",
        "                                                        num_labels = len(uniq_labels), \n",
        "                                                        output_attentions=False,\n",
        "                                                        output_hidden_states=False)\n",
        "\n",
        "# def model_init():\n",
        "#   model = DistilBertForTokenClassification.from_pretrained('distilbert-base-uncased', num_labels=len(uniq_labels))\n",
        "#   #model.to(device) # push to gpu\n",
        "#   return model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c0f791942ae424a89f884a04a423f22",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOtTQA3MuwDq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "47a107ed-34ed-4499-b0b1-0a0705ad05f6"
      },
      "source": [
        "folder_name = 'mitmovie_pt_' + model_name.replace('-', '_')\n",
        "folder_name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'mitmovie_pt_distilbert_base_uncased'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5APgzGuuFYkt"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# https://huggingface.co/transformers/main_classes/trainer.html\n",
        "# boiler plate code from huggingface to launch a trainer instance\n",
        "# sets directories and baseline configuration for batch sizes and weight decay\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = model_dir + folder_name + '/results',          # output directory\n",
        "    overwrite_output_dir = True,\n",
        "    evaluation_strategy='epoch',\n",
        "    num_train_epochs = 3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir = model_dir + folder_name + '/logs',            # directory for storing logs\n",
        "    logging_steps=100,\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    #model_init = model_init,\n",
        "    args = training_args,                  # training arguments, defined above\n",
        "    train_dataset = train_dataset,         # training dataset\n",
        "    eval_dataset = test_dataset             # evaluation dataset\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfrDO1yzvRT2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6e2d387-6a2a-4aca-82bb-ef58a20e574a"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla V100-SXM2-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OVkGs7KN0HY"
      },
      "source": [
        "#torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v5s1KNfZMVI"
      },
      "source": [
        "model.to(device);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGpVFJhSSmuB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "a586899f-f3be-4b2c-d89a-e879f100ee78"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "print('Time to train:', datetime.now() - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='1833' max='1833' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1833/1833 02:24, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.260431</td>\n",
              "      <td>0.282641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.168793</td>\n",
              "      <td>0.242859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.120766</td>\n",
              "      <td>0.243793</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time to train: 0:02:24.791234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiFQQkbOdq8A"
      },
      "source": [
        "#trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIbbyvLSsBBf"
      },
      "source": [
        "trainer.save_model(model_dir + folder_name + '/model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SczZnIKYWtzO"
      },
      "source": [
        "import os\n",
        "\n",
        "#os.makedirs(model_dir + 'distilbert_testing')\n",
        "\n",
        "# torch.save(model.state_dict(), model_dir + 'distilbert_testing/model.pth')\n",
        "# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "# model_to_save.save_pretrained(model_dir + 'distilbert_testing')\n",
        "# tokenizer.save_pretrained(model_dir + 'distilbert_testing')\n",
        "# #model.save_pretrained(model_dir + 'distilbert_testing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOKUjqjW_QNN"
      },
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn9PU9s-x_VZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "298b444d-257c-45c2-a952-a4c3e1ae47c7"
      },
      "source": [
        "folder_name = 'mitmovie_pt_' + model_name.replace('-', '_')\n",
        "folder_name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'mitmovie_pt_distilbert_base_uncased'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTGMOBuMSgRG"
      },
      "source": [
        "# from transformers import AutoModelForTokenClassification\n",
        "\n",
        "# # retreive the saved model \n",
        "# model = AutoModelForTokenClassification.from_pretrained(model_dir + folder_name + '/model') # "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPhv6K897Tki"
      },
      "source": [
        "#model.load_state_dict(torch.load(model_dir + 'distilbert_testing/model.pth', map_location='cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9tPdRbh8fPA"
      },
      "source": [
        "# model.eval();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1Znk8ZY5wel"
      },
      "source": [
        "#input_ids = torch.tensor([test_encodings['input_ids'][1]]).to('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noEO2FpO22Vi"
      },
      "source": [
        "# with torch.no_grad():\n",
        "#     output = model(input_ids)\n",
        "\n",
        "# pred_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CSJM4ne_1R9"
      },
      "source": [
        "# [id_to_label[label] for label in pred_indices.tolist()[0]][0:10], dataset['test_labels'][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9hbpuMAWFeC"
      },
      "source": [
        "# from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir = model_dir +  'mitmovie_pt_distilbert_uncased/results',          # output directory\n",
        "#     #overwrite_output_dir = True,\n",
        "#     evaluation_strategy='epoch',\n",
        "#     num_train_epochs=3,              # total number of training epochs\n",
        "#     per_device_train_batch_size=16,  # batch size per device during training\n",
        "#     per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "#     warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "#     weight_decay=0.01,               # strength of weight decay\n",
        "#     logging_dir = model_dir +  'mitmovie_pt_distilbert_uncased/logs',            # directory for storing logs\n",
        "#     logging_steps=10,\n",
        "# )\n",
        "\n",
        "# trainer = Trainer(\n",
        "#     model=model,                         \n",
        "#     args=training_args,                  # training arguments, defined above\n",
        "#     train_dataset = train_dataset,         # training dataset\n",
        "#     eval_dataset = test_dataset             # evaluation dataset\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fo_KqtmH8en",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "23043b7c-7d31-484d-8333-40b8a733c18a"
      },
      "source": [
        "# last layer output/activation has the shape of (batch_size, seq_len,num_of_labels)\n",
        "output, label_ids, metrics = trainer.predict(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [39/39 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F64ftH-dMZ7W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa9fe57d-180a-46be-b131-e361ae48f276"
      },
      "source": [
        "metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.24285870790481567}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-se8xMFiICsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de6e23c-2f21-45c3-cad8-86c1e7a4636c"
      },
      "source": [
        "# convert output which is logits to index of max logit\n",
        "preds = np.argmax(output, axis=2)\n",
        "preds.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2443, 43)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX-hj2tIIE0R"
      },
      "source": [
        "# https://medium.com/analytics-vidhya/named-entity-recognition-for-turkish-with-bert-f8ec04a31b0\n",
        "# this function formats the predictions by removing the padding\n",
        "# so that we can line it up directly with original data\n",
        "\n",
        "batch_size, seq_len = preds.shape\n",
        "\n",
        "# list of token-level predictions shape = (batch_size, seq_len)\n",
        "preds_list = [[] for _ in range(batch_size)]\n",
        "for i in range(batch_size):\n",
        "  for j in range(seq_len):\n",
        "    # ignore pad_tokens\n",
        "    if label_ids[i, j] != -100: # torch.nn.CrossEntropyLoss().ignore_index:\n",
        "      preds_list[i].append(id_to_label[preds[i][j]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkpkQCJRJXRW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662082e6-041a-4045-e5a0-9b5db2a81cb8"
      },
      "source": [
        "# you can see the number of predicted values and the actual values for a \n",
        "# given doc is the same, implying that the predictions line up\n",
        "# to the actuals because we set labels to -100 for [cls], [sep], and ## subwords\n",
        "len(preds_list[6]), len(dataset['test_tokens'][6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql44zqFdKFc-"
      },
      "source": [
        "preds_stretched = [label for doc in preds_list for label in doc]\n",
        "trues_stretched = [label for doc in dataset['test_labels'] for label in doc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G98QgmWhKcqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08d4ef55-daf5-4796-a8c1-beb73a5d62be"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "f = open(model_dir + folder_name + '/model'  + '/class_report_test.txt', 'w') \n",
        "\n",
        "class_report = classification_report(trues_stretched, preds_stretched)\n",
        "print(class_report, file=f ) \n",
        "\n",
        "f.close()\n",
        "\n",
        "print(class_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "          B-ACTOR       0.92      0.94      0.93       812\n",
            "      B-CHARACTER       0.69      0.62      0.65        90\n",
            "       B-DIRECTOR       0.93      0.88      0.90       456\n",
            "          B-GENRE       0.95      0.95      0.95      1117\n",
            "           B-PLOT       0.80      0.76      0.78       491\n",
            "         B-RATING       0.98      0.97      0.97       500\n",
            "B-RATINGS_AVERAGE       0.94      0.92      0.93       451\n",
            "         B-REVIEW       0.45      0.18      0.26        56\n",
            "           B-SONG       0.73      0.65      0.69        54\n",
            "          B-TITLE       0.86      0.93      0.89       562\n",
            "        B-TRAILER       0.82      0.90      0.86        30\n",
            "           B-YEAR       0.96      0.95      0.95       720\n",
            "          I-ACTOR       0.93      0.94      0.93       862\n",
            "      I-CHARACTER       0.67      0.49      0.57        75\n",
            "       I-DIRECTOR       0.92      0.88      0.90       496\n",
            "          I-GENRE       0.90      0.74      0.81       222\n",
            "           I-PLOT       0.80      0.70      0.75       496\n",
            "         I-RATING       0.94      0.95      0.94       226\n",
            "I-RATINGS_AVERAGE       0.84      0.94      0.89       403\n",
            "         I-REVIEW       0.00      0.00      0.00        45\n",
            "           I-SONG       0.86      0.75      0.80       119\n",
            "          I-TITLE       0.89      0.94      0.92       856\n",
            "        I-TRAILER       0.00      0.00      0.00         8\n",
            "           I-YEAR       0.97      0.98      0.97       610\n",
            "                O       0.97      0.98      0.97     14929\n",
            "\n",
            "         accuracy                           0.94     24686\n",
            "        macro avg       0.79      0.76      0.77     24686\n",
            "     weighted avg       0.94      0.94      0.94     24686\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a17S26duXsaw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091811e2-9fc6-4664-bf2b-20386703214b"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 20.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (0.17.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=533c9d01e3de1a920c630db12ee61939e57ea85a72e01f1de6dd83b3f483fc3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMutp6TOKx2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "641f8518-a01a-468e-cde7-8bf6be16b3c5"
      },
      "source": [
        "from seqeval.metrics import classification_report as classification_report_seqeval\n",
        "\n",
        "f = open(model_dir + folder_name + '/model'  + '/seq_class_report_test.txt', 'w') \n",
        "\n",
        "seq_class_report = classification_report_seqeval(dataset['test_labels'], preds_list)\n",
        "print(seq_class_report, file=f ) \n",
        "\n",
        "f.close() \n",
        "print(seq_class_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          ACTOR       0.89      0.92      0.91       812\n",
            "      CHARACTER       0.60      0.58      0.59        90\n",
            "       DIRECTOR       0.89      0.87      0.88       456\n",
            "          GENRE       0.92      0.93      0.93      1117\n",
            "           PLOT       0.71      0.74      0.72       491\n",
            "         RATING       0.95      0.94      0.94       500\n",
            "RATINGS_AVERAGE       0.84      0.87      0.85       451\n",
            "         REVIEW       0.18      0.07      0.10        56\n",
            "           SONG       0.59      0.54      0.56        54\n",
            "          TITLE       0.80      0.89      0.84       562\n",
            "        TRAILER       0.82      0.90      0.86        30\n",
            "           YEAR       0.94      0.94      0.94       720\n",
            "\n",
            "      micro avg       0.87      0.88      0.87      5339\n",
            "      macro avg       0.76      0.77      0.76      5339\n",
            "   weighted avg       0.86      0.88      0.87      5339\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBa-D65OXyly"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc20HA4OQd9h"
      },
      "source": [
        "## Bert Model\n",
        "\n",
        "Documentation for this model can be found: \n",
        "https://huggingface.co/transformers/model_doc/bert.html#overview\n",
        "\n",
        "Following HuggingFace distilbert tutorial: https://huggingface.co/transformers/custom_datasets.html#tok-ner\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMWbvrtoQd9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf64cb8-7e97-41b4-88e9-afc8ea4e7912"
      },
      "source": [
        "!pip install transformers==3.5.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 16.9MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 23.8MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 28.3MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 19.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 18.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 19.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 12.3MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 12.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92kB 12.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112kB 12.3MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 133kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153kB 12.3MB/s eta 0:00:01\r\u001b[K     |████                            | 163kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 174kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 184kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 204kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 215kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 225kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 235kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 245kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 256kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 266kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 276kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 286kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 296kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 307kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 317kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 327kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 337kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 348kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 358kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 368kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 378kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 389kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 399kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 409kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 419kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 430kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 440kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 450kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 460kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 471kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 481kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 491kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 501kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 512kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 522kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 532kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 542kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 552kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 563kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 573kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 583kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 593kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 604kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 614kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 624kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 634kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 645kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 655kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 665kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 675kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 686kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 696kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 706kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 716kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 727kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 737kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 747kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 757kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 768kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 778kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 788kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 798kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 808kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 819kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 829kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 839kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 849kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 860kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 870kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 880kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 890kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 901kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 911kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 921kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 931kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 942kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 952kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 962kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 972kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 983kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 993kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 12.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (0.7)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 59.4MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 62.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (2.23.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.5.1) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.5.1) (50.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.5.1) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.1) (0.17.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=a1d91e755b4327c6d486cabc1d7c462f1e3da8decd79d4b680643e9c6998677f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za4-_-AEQd9x"
      },
      "source": [
        "### Encode Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFqt4gnSQd9y"
      },
      "source": [
        "# get the set of unique labels in the movie dataset\n",
        "uniq_labels = set([label for doc in dataset['train_labels'] for label in doc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c_nyRO8Qd94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f3ae2f-82c2-49b5-e06f-739c0abaaf4f"
      },
      "source": [
        "# assign a number to each label\n",
        "label_encoding = {label: id for id, label in enumerate(uniq_labels)}\n",
        "label_encoding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-ACTOR': 13,\n",
              " 'B-CHARACTER': 24,\n",
              " 'B-DIRECTOR': 19,\n",
              " 'B-GENRE': 14,\n",
              " 'B-PLOT': 12,\n",
              " 'B-RATING': 20,\n",
              " 'B-RATINGS_AVERAGE': 1,\n",
              " 'B-REVIEW': 2,\n",
              " 'B-SONG': 3,\n",
              " 'B-TITLE': 10,\n",
              " 'B-TRAILER': 6,\n",
              " 'B-YEAR': 15,\n",
              " 'I-ACTOR': 5,\n",
              " 'I-CHARACTER': 23,\n",
              " 'I-DIRECTOR': 4,\n",
              " 'I-GENRE': 7,\n",
              " 'I-PLOT': 0,\n",
              " 'I-RATING': 8,\n",
              " 'I-RATINGS_AVERAGE': 21,\n",
              " 'I-REVIEW': 9,\n",
              " 'I-SONG': 16,\n",
              " 'I-TITLE': 18,\n",
              " 'I-TRAILER': 11,\n",
              " 'I-YEAR': 22,\n",
              " 'O': 17}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j4Tq1N8Qd99"
      },
      "source": [
        "### Encode Texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tym3XvYfQd9-"
      },
      "source": [
        "To encode the texts, we have to use the same Tokenizer that DistilBert was trained on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ1YS3YJQd9_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "e1cc38313b6d462f9464f91c178bbb52",
            "550d64db05b8439abb69dc8f1426a4be",
            "d409c00d91d14545afee4bf2922c57bc",
            "13271d762bc142d4bcca58fee9d1853c",
            "b2cb215b84b6490d8237359fbc7a3f4c",
            "b3273dfa81f3485fab1b609fa0e30160",
            "2fd24205c95e4a0e8c7428e133328271",
            "e6887af4f6354162afe7c3a076e35e55",
            "28aa0edec8ae4441922251d9c2437c85",
            "a19b984715774fd2b4c3736cc5c7dab2",
            "4a71e1a5f6dc4b75a7da11b4a1e7afcd",
            "1a365a1043a3401a9ae6d791bad80f01",
            "b50dff8c05694a4e8fcc4a2b01254aa4",
            "8eec1bf1733447cf8fa78b25d4bc9adf",
            "8830ff252340472aa3468d0d7abeb1ef",
            "29139f2bbf8a4868a89ada4f0d2ccf80"
          ]
        },
        "outputId": "f52a05e3-4038-40b5-8a9a-a0e1d15ecbae"
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-large-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1cc38313b6d462f9464f91c178bbb52",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28aa0edec8ae4441922251d9c2437c85",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsxM2yFzQd-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b4602e6-4fc2-4c17-edcd-3e0237a5b118"
      },
      "source": [
        "print('There are %s words in this tokenizer object' % tokenizer.vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 30522 words in this tokenizer object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67930r_5Qd-J"
      },
      "source": [
        "# use the tokenizer to encode the texts \n",
        "train_encodings = tokenizer(dataset['train_tokens'], \n",
        "                            is_split_into_words=True, \n",
        "                            return_offsets_mapping=True, \n",
        "                            padding=True, \n",
        "                            truncation=True)\n",
        "\n",
        "test_encodings = tokenizer(dataset['test_tokens'], \n",
        "                           is_split_into_words=True, \n",
        "                           return_offsets_mapping=True, \n",
        "                           padding=True, \n",
        "                           truncation=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5kQAJmqQd-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb7e82a-1125-4cbd-ac5e-bb8d58f652b4"
      },
      "source": [
        "train_encodings.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD7bpKjfQd-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89946926-d11e-4ff5-c4da-5210d5f1b357"
      },
      "source": [
        "# make sure same number of docs\n",
        "len(train_encodings['input_ids']), len(dataset['train_tokens'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9775, 9775)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqmK7jArQd-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "838a1706-1751-46f1-fffc-c667ecf42f6a"
      },
      "source": [
        "dataset['train_tokens'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'movies', 'star', 'bruce', 'willis']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ms5wc0hQd-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "143acd01-3390-4af1-a42a-026f1d6ec1a8"
      },
      "source": [
        "# preview what the encoded result looks like\n",
        "list(zip(train_encodings['input_ids'][0][0:12], train_encodings['attention_mask'][0][0:12], train_encodings['offset_mapping'][0][0:12]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(101, 1, (0, 0)),\n",
              " (2054, 1, (0, 4)),\n",
              " (5691, 1, (0, 6)),\n",
              " (2732, 1, (0, 4)),\n",
              " (5503, 1, (0, 5)),\n",
              " (12688, 1, (0, 6)),\n",
              " (102, 1, (0, 0)),\n",
              " (0, 0, (0, 0)),\n",
              " (0, 0, (0, 0)),\n",
              " (0, 0, (0, 0)),\n",
              " (0, 0, (0, 0)),\n",
              " (0, 0, (0, 0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtUHIGPAQd-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b08945-1e5d-438c-f758-5296a6ef7ee6"
      },
      "source": [
        "# the model expects all docs to be same length (51) \n",
        "# the attention mask will tell the model to ignore the padding with zeros\n",
        "print('Length of sequences is %s ' % len(train_encodings['input_ids'][1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of sequences is 51 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZWiPdw6Qd-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f751dc-ed87-499d-8c47-f23fce77bb21"
      },
      "source": [
        "# first document in dataset\n",
        "print( dataset['train_tokens'][0] )\n",
        "\n",
        "# check out new tokenization result as words\n",
        "print( tokenizer.convert_ids_to_tokens( train_encodings['input_ids'][0][0:9]) )\n",
        "\n",
        "# check out new tokenization result as ids\n",
        "print( [val for val in train_encodings['input_ids'][0] if val != 0] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what', 'movies', 'star', 'bruce', 'willis']\n",
            "['[CLS]', 'what', 'movies', 'star', 'bruce', 'willis', '[SEP]', '[PAD]', '[PAD]']\n",
            "[101, 2054, 5691, 2732, 5503, 12688, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWUeTlGBQd-t"
      },
      "source": [
        "find_subwords = []\n",
        "for i, offset_list in enumerate(train_encodings['offset_mapping']):\n",
        "  for j, offset_tuple in enumerate(offset_list):\n",
        "    if offset_tuple[0] != 0:\n",
        "      find_subwords.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k17vdwnxQd-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e9d7fa9-9d56-478f-da66-0a27f7eeee50"
      },
      "source": [
        "np.unique(find_subwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,    2,    3, ..., 9752, 9767, 9772])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPuQ_NjmQd-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f2be533-80f5-46fb-97ae-b3c84fc0b23e"
      },
      "source": [
        "dataset['train_tokens'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['show', 'me', 'films', 'with', 'drew', 'barrymore', 'from', 'the', '1980s']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWYnCn8kQd_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba3c598-3fff-473e-ae1d-a65de755a229"
      },
      "source": [
        "list(zip(train_encodings['input_ids'][1][0:12], train_encodings['attention_mask'][1][0:12], train_encodings['offset_mapping'][1][0:12]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(101, 1, (0, 0)),\n",
              " (2265, 1, (0, 4)),\n",
              " (2033, 1, (0, 2)),\n",
              " (3152, 1, (0, 5)),\n",
              " (2007, 1, (0, 4)),\n",
              " (3881, 1, (0, 4)),\n",
              " (6287, 1, (0, 5)),\n",
              " (5974, 1, (5, 9)),\n",
              " (2013, 1, (0, 4)),\n",
              " (1996, 1, (0, 3)),\n",
              " (3865, 1, (0, 5)),\n",
              " (102, 1, (0, 0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WGoEA58RtaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b468fce8-7fb8-4cbd-f2c4-edaba359e34d"
      },
      "source": [
        "[tokenizer.convert_ids_to_tokens(val) for val in train_encodings['input_ids'][1][0:12]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'show',\n",
              " 'me',\n",
              " 'films',\n",
              " 'with',\n",
              " 'drew',\n",
              " 'barry',\n",
              " '##more',\n",
              " 'from',\n",
              " 'the',\n",
              " '1980s',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vryYqZKYQd_P"
      },
      "source": [
        "### Adjust Labels for Vocab Offset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOmhSye2Qd_Q"
      },
      "source": [
        "In the print out above you can see that \"barrymore\" gets transformed into \"barry\", \"##more\". This is because the name is not in the vocabulary of the model, however, those small subwords \"barry\" and \"##more\" are. So the offsetting notifies the model of this splitting of the word. However, we have to adjust the labels now to account for this separation. \n",
        "\n",
        "Based on https://datascience.stackexchange.com/questions/69640/what-should-be-the-labels-for-subword-tokens-in-bert-for-ner-task we will not drag the label to the new subword feature because that would introduce more instances of that class and change the number of support instances thus making the models difficult to compare. \n",
        "\n",
        "Also some comments to consider for an alternative strategy: https://github.com/google-research/bert/issues/646\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duIlrWmAQd_R"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def adjust_labels_for_offset(original_labels, label_dictionary, encodings):\n",
        "\n",
        "    # convert to the numeric encoding of the label\n",
        "    labels = [[label_dictionary[label] for label in doc] for doc in original_labels]\n",
        "\n",
        "    encoded_labels = []\n",
        "    for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
        "\n",
        "        # create an empty array of -100\n",
        "        doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
        "        arr_offset = np.array(doc_offset)\n",
        "\n",
        "        # set labels whose first offset position is 0 and the second is not 0\n",
        "        doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
        "        encoded_labels.append(doc_enc_labels.tolist())\n",
        "\n",
        "    return encoded_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZtJLk38Qd_V"
      },
      "source": [
        "train_labels = adjust_labels_for_offset(dataset['train_labels'], \n",
        "                                        label_encoding, \n",
        "                                        train_encodings)\n",
        "\n",
        "test_labels = adjust_labels_for_offset(dataset['test_labels'],\n",
        "                                      label_encoding, \n",
        "                                      test_encodings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k7kCcnWQd_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a95262-c95a-4746-8459-237598176736"
      },
      "source": [
        "id_to_label = {id: label for (label,id) in label_encoding.items()}\n",
        "id_to_label[-100] = 'X'\n",
        "\n",
        "#print( tokenizer.convert_ids_to_tokens(encoding_example) )\n",
        "#print([id_to_label[id] for id in train_labels[0][0:9]])\n",
        "list(zip( tokenizer.convert_ids_to_tokens(train_encodings['input_ids'][0][0:15]), [id_to_label[id] for id in train_labels[0][0:15]], train_labels[0][0:15] )) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('[CLS]', 'X', -100),\n",
              " ('what', 'O', 17),\n",
              " ('movies', 'O', 17),\n",
              " ('star', 'O', 17),\n",
              " ('bruce', 'B-ACTOR', 13),\n",
              " ('willis', 'I-ACTOR', 5),\n",
              " ('[SEP]', 'X', -100),\n",
              " ('[PAD]', 'X', -100),\n",
              " ('[PAD]', 'X', -100),\n",
              " ('[PAD]', 'X', -100),\n",
              " ('[PAD]', 'X', -100),\n",
              " ('[PAD]', 'X', -100),\n",
              " ('[PAD]', 'X', -100),\n",
              " ('[PAD]', 'X', -100),\n",
              " ('[PAD]', 'X', -100)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cSAvc34Qd_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e264f2-82e6-4ea2-9fd5-810b387f6d3c"
      },
      "source": [
        "np.unique(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-100,    0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
              "         10,   11,   12,   13,   14,   15,   16,   17,   18,   19,   20,\n",
              "         21,   22,   23,   24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0EIH6mTQd_u"
      },
      "source": [
        "### Prepare Pytorch Datasets\n",
        "\n",
        "https://huggingface.co/transformers/custom_datasets.html#ft-trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNcRNGstQd_v"
      },
      "source": [
        "import torch\n",
        "\n",
        "# pytorch is expecting a certain type of dataset \n",
        "\n",
        "class pt_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# remove the offset_mapping\n",
        "train_encodings.pop(\"offset_mapping\") \n",
        "test_encodings.pop(\"offset_mapping\")\n",
        "\n",
        "train_dataset = pt_dataset(train_encodings, train_labels)\n",
        "test_dataset = pt_dataset(test_encodings, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTsbw57CQd_6"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVznG5v5Qd_7"
      },
      "source": [
        "from transformers import BertForTokenClassification\n",
        "\n",
        "# load the pretrained model from huggingface\n",
        "#model = BertForTokenClassification.from_pretrained('bert-large-uncased', num_labels=len(uniq_labels), cache_dir= model_dir +  'mitmovie_pt_bert_uncased/cache')\n",
        "def model_init():\n",
        "  model = BertForTokenClassification.from_pretrained('bert-large-uncased', num_labels=len(uniq_labels))\n",
        "  #model.to(device) # push to gpu\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku-_s5aIOF7T",
        "outputId": "bc9d7224-aa63-4a58-d1f5-97ea371a6ccb"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 28.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 29.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 20.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (0.17.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=c5f93fe9ee9c175e9802a6b7749d9b4fbe30b4387a2f897f7ba4b74bd667589f\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXm-KXNmn0LQ"
      },
      "source": [
        "#from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "# function for computing monitoring metrics during training\n",
        "\n",
        "def compute_metrics(p):\n",
        "\n",
        "        predictions, labels = p\n",
        "        predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "        # Remove ignored index (special tokens)\n",
        "        true_predictions = [\n",
        "            [id_to_label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "            for prediction, label in zip(predictions, labels)\n",
        "        ]\n",
        "        true_labels = [\n",
        "            [id_to_label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "            for prediction, label in zip(predictions, labels)\n",
        "        ]\n",
        "\n",
        "        preds_stretched = [label for doc in true_predictions for label in doc]\n",
        "        trues_stretched = [label for doc in true_labels for label in doc]\n",
        "\n",
        "        return {\n",
        "            \"accuracy_score\": accuracy_score(trues_stretched, preds_stretched),\n",
        "            \"precision\": precision_score(trues_stretched, preds_stretched, average='macro'),\n",
        "            \"recall\": recall_score(trues_stretched, preds_stretched, average='macro'),\n",
        "            \"f1\": f1_score(trues_stretched, preds_stretched, average='macro'),\n",
        "        }\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXO-MSQLQeAD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "88281e681de446a99d3fadfb323c49f2",
            "dc884e441d8c42419863897f6f228862",
            "3826d7a37acf4b2fbf6f355275534779",
            "da96d13b08dd4130a7362a54a36d4dc9",
            "36f4492397134ad081c9004531553c50",
            "a17721e8df9c4c92a0f42fcc8ab417ca",
            "8ae9193b81ab48e38ce73f7750d749f5",
            "455466604bfd46e38a5b3263fcdc49d4",
            "ca8b072dd3744da1b3ffaaa3240d7fc0",
            "f53fc2bb69b84cf6ad1c0866fa48c624",
            "b4eaa799e8c741a6b488927771459124",
            "6681137b579548e59fb8103cbd5fa9ec",
            "d208c7d93ebe4f6394f0bbcb0412ac94",
            "10629d6a08f54e23b7dbf17e8f159024",
            "dfeafa3f1d114aa08238cce8b3184475",
            "c12d99461083489a9597f59726d1b5d8"
          ]
        },
        "outputId": "182c1593-0d9d-44fc-a57f-aa1be2682330"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# boiler plate code from huggingface to launch a trainer instance\n",
        "# sets directories and baseline configuration for batch sizes and weight decay\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = model_dir +  'mitmovie_pt_bert_uncased/results',          # output directory\n",
        "    overwrite_output_dir = True,\n",
        "    num_train_epochs = 10,              # total number of training epochs\n",
        "    evaluation_strategy = 'epoch',\n",
        "    per_device_train_batch_size = 32,  # batch size per device during training\n",
        "    per_device_eval_batch_size = 64,   # batch size for evaluation\n",
        "    warmup_steps= 500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay= 0.00,               # strength of weight decay\n",
        "    learning_rate = 3e-5,\n",
        "    logging_dir = model_dir +  'mitmovie_pt_bert_uncased/logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    #load_best_model_at_end = True,\n",
        "    #metric_for_best_model = 'eval_f1'\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    #model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    model_init = model_init,\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset = train_dataset,         # training dataset\n",
        "    eval_dataset = test_dataset,             # evaluation dataset\n",
        "    compute_metrics = compute_metrics\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88281e681de446a99d3fadfb323c49f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=434.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca8b072dd3744da1b3ffaaa3240d7fc0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KSI8xCWUKpZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "65c1860c-de49-4e2e-b606-0a30d6363c2f"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla V100-SXM2-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAhRPVdWQeAJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "6b34086d-09e5-4640-cb5f-72d80b9b1615"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "# record the results for each run\n",
        "training_results = trainer.train()\n",
        "\n",
        "print('Time to train:', datetime.now() - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='3060' max='3060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3060/3060 27:39, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy Score</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.283661</td>\n",
              "      <td>0.289162</td>\n",
              "      <td>0.934052</td>\n",
              "      <td>0.772672</td>\n",
              "      <td>0.714371</td>\n",
              "      <td>0.731690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.254776</td>\n",
              "      <td>0.251477</td>\n",
              "      <td>0.941789</td>\n",
              "      <td>0.782420</td>\n",
              "      <td>0.783112</td>\n",
              "      <td>0.777286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.161359</td>\n",
              "      <td>0.253897</td>\n",
              "      <td>0.943166</td>\n",
              "      <td>0.797175</td>\n",
              "      <td>0.772685</td>\n",
              "      <td>0.780664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.095200</td>\n",
              "      <td>0.269191</td>\n",
              "      <td>0.944017</td>\n",
              "      <td>0.814949</td>\n",
              "      <td>0.776235</td>\n",
              "      <td>0.785371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.073114</td>\n",
              "      <td>0.283807</td>\n",
              "      <td>0.945759</td>\n",
              "      <td>0.801928</td>\n",
              "      <td>0.787206</td>\n",
              "      <td>0.792692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.049426</td>\n",
              "      <td>0.303408</td>\n",
              "      <td>0.944543</td>\n",
              "      <td>0.798888</td>\n",
              "      <td>0.794230</td>\n",
              "      <td>0.795184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.023676</td>\n",
              "      <td>0.332908</td>\n",
              "      <td>0.945192</td>\n",
              "      <td>0.799014</td>\n",
              "      <td>0.791555</td>\n",
              "      <td>0.792475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.022968</td>\n",
              "      <td>0.362411</td>\n",
              "      <td>0.944098</td>\n",
              "      <td>0.838828</td>\n",
              "      <td>0.799285</td>\n",
              "      <td>0.802444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.022095</td>\n",
              "      <td>0.391702</td>\n",
              "      <td>0.945192</td>\n",
              "      <td>0.807565</td>\n",
              "      <td>0.791872</td>\n",
              "      <td>0.797737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.007721</td>\n",
              "      <td>0.401736</td>\n",
              "      <td>0.945313</td>\n",
              "      <td>0.844477</td>\n",
              "      <td>0.793222</td>\n",
              "      <td>0.802800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to train: 0:27:52.543799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mh1M0DQQeAO"
      },
      "source": [
        "trainer.save_model(model_dir + 'mitmovie_pt_bert_uncased/model')\n",
        "#model.save_pretrained(model_dir + 'mitmovie_pt_bert_uncased/model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLSmNtCEQeAU"
      },
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcFGGPUfz2YK"
      },
      "source": [
        "# model = None\n",
        "# trainer = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_jl59LhQeAU"
      },
      "source": [
        "# from transformers import BertForTokenClassification\n",
        "\n",
        "# # retreive the saved model \n",
        "# model = BertForTokenClassification.from_pretrained(model_dir + 'mitmovie_pt_bert_uncased/model', num_labels=len(uniq_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8usYKhiQeAa"
      },
      "source": [
        "# trainer = Trainer(\n",
        "#     model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "#     args=training_args,                  # training arguments, defined above\n",
        "#     train_dataset = train_dataset,         # training dataset\n",
        "#     eval_dataset = test_dataset             # evaluation dataset\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm-3KdVSQeAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a771e73-2dc8-4a48-d9ab-06f3ca9ed8b2"
      },
      "source": [
        "# last layer output/activation has the shape of (batch_size, seq_len,num_of_labels)\n",
        "output, label_ids, metrics = trainer.predict(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [39/39 00:05]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSeVWJ4rQeAr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a83ba8e-51c1-4d11-8ebe-a3bd9a7e8a63"
      },
      "source": [
        "metrics\n",
        "# 0.24249209463596344"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy_score': 0.9453131329498501,\n",
              " 'eval_f1': 0.802799642924628,\n",
              " 'eval_loss': 0.40173640847206116,\n",
              " 'eval_precision': 0.8444770060074938,\n",
              " 'eval_recall': 0.7932217764158566}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGjytd3PQeBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e5e2e15-fda2-46b7-c348-db65cae572e5"
      },
      "source": [
        "# convert output which is logits to index of max logit\n",
        "preds = np.argmax(output, axis=2)\n",
        "preds.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2443, 43)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP9qAJtoQeBL"
      },
      "source": [
        "# https://medium.com/analytics-vidhya/named-entity-recognition-for-turkish-with-bert-f8ec04a31b0\n",
        "# this function formats the predictions by removing the padding\n",
        "# so that we can line it up directly with original data\n",
        "\n",
        "batch_size, seq_len = preds.shape\n",
        "\n",
        "# list of token-level predictions shape = (batch_size, seq_len)\n",
        "preds_list = [[] for _ in range(batch_size)]\n",
        "for i in range(batch_size):\n",
        "  for j in range(seq_len):\n",
        "    # ignore pad_tokens\n",
        "    if label_ids[i, j] != -100: # torch.nn.CrossEntropyLoss().ignore_index:\n",
        "      preds_list[i].append(id_to_label[preds[i][j]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vimb2E4ZQeBQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b0c678b-6c00-490e-cb4b-1193b443667f"
      },
      "source": [
        "# you can see the number of predicted values and the actual values for a \n",
        "# given doc is the same, implying that the predictions line up\n",
        "# to the actuals because we set labels to -100 for [cls], [sep], and ## subwords\n",
        "len(preds_list[6]), len(dataset['test_tokens'][6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RBmbdRhQeBY"
      },
      "source": [
        "preds_stretched = [label for doc in preds_list for label in doc]\n",
        "trues_stretched = [label for doc in dataset['test_labels'] for label in doc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC7ooj2kQeBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179c666c-9798-432b-dd6c-d49586d6cff2"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "f = open(model_dir + 'mitmovie_pt_bert_uncased/model'  + '/class_report_test.txt', 'w') \n",
        "\n",
        "class_report = classification_report(trues_stretched, preds_stretched)\n",
        "print(class_report, file=f ) \n",
        "\n",
        "f.close()\n",
        "\n",
        "print(class_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "          B-ACTOR       0.94      0.96      0.95       812\n",
            "      B-CHARACTER       0.66      0.74      0.70        90\n",
            "       B-DIRECTOR       0.94      0.91      0.92       456\n",
            "          B-GENRE       0.94      0.96      0.95      1117\n",
            "           B-PLOT       0.76      0.76      0.76       491\n",
            "         B-RATING       0.96      0.96      0.96       500\n",
            "B-RATINGS_AVERAGE       0.94      0.91      0.92       451\n",
            "         B-REVIEW       0.40      0.45      0.42        56\n",
            "           B-SONG       0.73      0.76      0.75        54\n",
            "          B-TITLE       0.90      0.91      0.90       562\n",
            "        B-TRAILER       0.84      0.90      0.87        30\n",
            "           B-YEAR       0.93      0.96      0.94       720\n",
            "          I-ACTOR       0.94      0.95      0.94       862\n",
            "      I-CHARACTER       0.66      0.60      0.63        75\n",
            "       I-DIRECTOR       0.95      0.89      0.92       496\n",
            "          I-GENRE       0.84      0.76      0.80       222\n",
            "           I-PLOT       0.79      0.69      0.73       496\n",
            "         I-RATING       0.93      0.92      0.93       226\n",
            "I-RATINGS_AVERAGE       0.90      0.90      0.90       403\n",
            "         I-REVIEW       0.35      0.16      0.22        45\n",
            "           I-SONG       0.96      0.77      0.86       119\n",
            "          I-TITLE       0.93      0.93      0.93       856\n",
            "        I-TRAILER       1.00      0.12      0.22         8\n",
            "           I-YEAR       0.96      0.98      0.97       610\n",
            "                O       0.97      0.98      0.97     14929\n",
            "\n",
            "         accuracy                           0.95     24686\n",
            "        macro avg       0.84      0.79      0.80     24686\n",
            "     weighted avg       0.94      0.95      0.94     24686\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2RQDbxXQeBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09391b63-7592-44f7-9969-bcab7d7835f9"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc1x1KxWQeBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b87a20f8-991f-4eb0-efc5-62c7571e4dd6"
      },
      "source": [
        "from seqeval.metrics import classification_report as classification_report_seqeval\n",
        "\n",
        "f = open(model_dir + 'mitmovie_pt_bert_uncased/model'  + '/seq_class_report_test.txt', 'w') \n",
        "\n",
        "seq_class_report = classification_report_seqeval(dataset['test_labels'], preds_list)\n",
        "print(seq_class_report, file=f ) \n",
        "\n",
        "f.close() \n",
        "print(seq_class_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          ACTOR       0.92      0.95      0.94       812\n",
            "      CHARACTER       0.62      0.72      0.67        90\n",
            "       DIRECTOR       0.93      0.90      0.92       456\n",
            "          GENRE       0.90      0.93      0.91      1117\n",
            "           PLOT       0.69      0.74      0.71       491\n",
            "         RATING       0.93      0.94      0.93       500\n",
            "RATINGS_AVERAGE       0.87      0.86      0.86       451\n",
            "         REVIEW       0.34      0.39      0.37        56\n",
            "           SONG       0.61      0.67      0.64        54\n",
            "          TITLE       0.86      0.89      0.88       562\n",
            "        TRAILER       0.82      0.90      0.86        30\n",
            "           YEAR       0.92      0.95      0.93       720\n",
            "\n",
            "      micro avg       0.87      0.89      0.88      5339\n",
            "      macro avg       0.79      0.82      0.80      5339\n",
            "   weighted avg       0.87      0.89      0.88      5339\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvaqaiCRQeB0"
      },
      "source": [
        "with open(model_dir + 'mitmovie_pt_bert_uncased/' + 'preds_stretched.pickle', 'wb') as handle:\n",
        "    pickle.dump(preds_stretched, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open(model_dir + 'mitmovie_pt_bert_uncased/' + 'trues_stretched.pickle', 'wb') as handle:\n",
        "    pickle.dump(trues_stretched, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOfRG1kgZBfe"
      },
      "source": [
        "## Roberta Model\n",
        "\n",
        "Documentation for this model can be found: \n",
        "https://huggingface.co/transformers/model_doc/roberta.html\n",
        "\n",
        "Following HuggingFace distilbert tutorial: https://huggingface.co/transformers/custom_datasets.html#tok-ner\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aueDVMHZBfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1416c2e-6120-40b7-facb-0a672253ce1b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmKURmzLZBfq"
      },
      "source": [
        "### Encode Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbP63ZwFZBfr"
      },
      "source": [
        "# get the set of unique labels in the movie dataset\n",
        "uniq_labels = set([label for doc in dataset['train_labels'] for label in doc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_KTWgN7ZBfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cecbf85a-f0bf-44a9-c6d5-fed246fe8716"
      },
      "source": [
        "# assign a number to each label\n",
        "label_encoding = {label: id for id, label in enumerate(uniq_labels)}\n",
        "label_encoding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-ACTOR': 13,\n",
              " 'B-CHARACTER': 12,\n",
              " 'B-DIRECTOR': 8,\n",
              " 'B-GENRE': 19,\n",
              " 'B-PLOT': 23,\n",
              " 'B-RATING': 16,\n",
              " 'B-RATINGS_AVERAGE': 14,\n",
              " 'B-REVIEW': 4,\n",
              " 'B-SONG': 7,\n",
              " 'B-TITLE': 17,\n",
              " 'B-TRAILER': 22,\n",
              " 'B-YEAR': 18,\n",
              " 'I-ACTOR': 6,\n",
              " 'I-CHARACTER': 5,\n",
              " 'I-DIRECTOR': 24,\n",
              " 'I-GENRE': 11,\n",
              " 'I-PLOT': 0,\n",
              " 'I-RATING': 3,\n",
              " 'I-RATINGS_AVERAGE': 2,\n",
              " 'I-REVIEW': 9,\n",
              " 'I-SONG': 10,\n",
              " 'I-TITLE': 20,\n",
              " 'I-TRAILER': 1,\n",
              " 'I-YEAR': 15,\n",
              " 'O': 21}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YscwZw7xZBf0"
      },
      "source": [
        "### Encode Texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f1p_nbLZBf2"
      },
      "source": [
        "To encode the texts, we have to use the same Tokenizer that Roberta was trained on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvx0t1ItZBf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "75b46960b609431386927f9b62dd9e0c",
            "579f4167af7240c0bfd5f973d34858ae",
            "37c4e4e5a03f41df9d91c249c40786ae",
            "39038a4a11a2405d9273f1308c0da2ac",
            "639c567cfb844954bcf778052b8e2edf",
            "76f093e5506f436f8b1c9b105088539f",
            "922b7c7071574f66941cfe864fcfa699",
            "69bac9665511422a97a834084a531205",
            "b46e145ab8114505ba37a281a6b9deb9",
            "54a44ccdd4824708922466888375360a",
            "5171c9f82f7546bf9586bde775a37053",
            "c551399998b246a9a35888ebf3a6568d",
            "c6c143339b334486a80b0982070ca10e",
            "ed83b42b39604eb597bcf81553e24c03",
            "3ada8ab0bb53498d8fb726f8148e758b",
            "d3973f58b5734aaf876fd242c9a5f88b",
            "5d892f57fae54fa48b5e8f35fd2ae3b1",
            "69d57893af4d4004844f9e4c7d93a8d9",
            "5a8fb41adf534f72b97cd68e09f8b5ce",
            "54a3627948c84769ab1f5dc6c0ea188b",
            "e57a0c5655444f90927635e19577e0f2",
            "8d28b4c57b7c4105877709d94eb945fa",
            "b913ab31526641a0b4fec9ebaad9b07d",
            "a838ab51697d455294b54a03e6cb5443"
          ]
        },
        "outputId": "c6d182ed-0925-4388-b9d2-e356e121f78c"
      },
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-large', add_prefix_space=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75b46960b609431386927f9b62dd9e0c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b46e145ab8114505ba37a281a6b9deb9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d892f57fae54fa48b5e8f35fd2ae3b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWgZBes1ZBf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "613fff6a-4314-4678-d387-6535380372fc"
      },
      "source": [
        "print('There are %s words in this tokenizer object' % tokenizer.vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 50265 words in this tokenizer object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT4gHNn55C0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4ffdc9-331f-438d-bff8-47594f38e768"
      },
      "source": [
        "toked = tokenizer.tokenize('what movies start bruce willis')\n",
        "tokenizer('what movies start bruce willis')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [0, 99, 4133, 386, 29435, 1755, 40, 354, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvXDv52RZBf_"
      },
      "source": [
        "# use the tokenizer to encode the texts \n",
        "train_encodings = tokenizer(dataset['train_tokens'], \n",
        "                            is_split_into_words=True, \n",
        "                            return_offsets_mapping=True, \n",
        "                            padding=True, \n",
        "                            truncation=True)\n",
        "\n",
        "test_encodings = tokenizer(dataset['test_tokens'], \n",
        "                           is_split_into_words=True, \n",
        "                           return_offsets_mapping=True, \n",
        "                           padding=True, \n",
        "                           truncation=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0LK58RwZBgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805732ea-c1c1-4348-ee4e-3d0bfd5aa7b8"
      },
      "source": [
        "train_encodings.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'offset_mapping'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7Bia2iyZBgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddc98e27-46e5-4019-b6cc-f01fde8fb04b"
      },
      "source": [
        "# make sure same number of docs\n",
        "len(train_encodings['input_ids']), len(dataset['train_tokens'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9775, 9775)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI-F05n1ZBgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e5977d5-e591-4166-ff2d-cf49083cc653"
      },
      "source": [
        "dataset['train_tokens'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'movies', 'star', 'bruce', 'willis']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkI9LoB1ZBgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c78efead-a4ee-44a6-86f1-670a5515b44a"
      },
      "source": [
        "# preview what the encoded result looks like\n",
        "list(zip(train_encodings['input_ids'][0][0:12], train_encodings['attention_mask'][0][0:12], train_encodings['offset_mapping'][0][0:12]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1, (0, 0)),\n",
              " (99, 1, (1, 4)),\n",
              " (4133, 1, (1, 6)),\n",
              " (999, 1, (1, 4)),\n",
              " (29435, 1, (1, 3)),\n",
              " (1755, 1, (3, 5)),\n",
              " (40, 1, (1, 4)),\n",
              " (354, 1, (4, 6)),\n",
              " (2, 1, (0, 0)),\n",
              " (1, 0, (0, 0)),\n",
              " (1, 0, (0, 0)),\n",
              " (1, 0, (0, 0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOIIRXu0ZBgY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "335982a8-139e-48ab-f9e8-fdf993416616"
      },
      "source": [
        "# the model expects all docs to be same length (56) \n",
        "# the attention mask will tell the model to ignore the padding with zeros\n",
        "print('Length of sequences is %s ' % len(train_encodings['input_ids'][1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of sequences is 56 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5JjRgqsZBgb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0729f455-1cbe-4775-a1d3-f494fac73f3e"
      },
      "source": [
        "# first document in dataset\n",
        "print( dataset['train_tokens'][0] )\n",
        "\n",
        "# check out new tokenization result as words\n",
        "print( tokenizer.convert_ids_to_tokens( train_encodings['input_ids'][0][0:9]) )\n",
        "\n",
        "# check out new tokenization result as ids\n",
        "print( [val for val in train_encodings['input_ids'][0] if val != 0] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what', 'movies', 'star', 'bruce', 'willis']\n",
            "['<s>', 'Ġwhat', 'Ġmovies', 'Ġstar', 'Ġbru', 'ce', 'Ġwill', 'is', '</s>']\n",
            "[99, 4133, 999, 29435, 1755, 40, 354, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn_owGEAZBgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f8fe37-f2f8-4691-8fee-f85cdd429e55"
      },
      "source": [
        "dataset['train_tokens'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['show', 'me', 'films', 'with', 'drew', 'barrymore', 'from', 'the', '1980s']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAAN9hVTZBgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b90f1e6-a126-470c-c6e0-c687a1a43074"
      },
      "source": [
        "list(zip(train_encodings['input_ids'][1][0:15], train_encodings['attention_mask'][1][0:15], train_encodings['offset_mapping'][1][0:15]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1, (0, 0)),\n",
              " (311, 1, (1, 4)),\n",
              " (162, 1, (1, 2)),\n",
              " (3541, 1, (1, 5)),\n",
              " (19, 1, (1, 4)),\n",
              " (4855, 1, (1, 4)),\n",
              " (2003, 1, (1, 3)),\n",
              " (1506, 1, (3, 5)),\n",
              " (4321, 1, (5, 9)),\n",
              " (31, 1, (1, 4)),\n",
              " (5, 1, (1, 3)),\n",
              " (5114, 1, (1, 4)),\n",
              " (29, 1, (4, 5)),\n",
              " (2, 1, (0, 0)),\n",
              " (1, 0, (0, 0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6kCl7lyZBgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337d9223-b8a1-44d9-d174-2d8bea76c65e"
      },
      "source": [
        "[(val,tokenizer.convert_ids_to_tokens(val)) for val in train_encodings['input_ids'][1][0:15]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, '<s>'),\n",
              " (311, 'Ġshow'),\n",
              " (162, 'Ġme'),\n",
              " (3541, 'Ġfilms'),\n",
              " (19, 'Ġwith'),\n",
              " (4855, 'Ġdrew'),\n",
              " (2003, 'Ġbar'),\n",
              " (1506, 'ry'),\n",
              " (4321, 'more'),\n",
              " (31, 'Ġfrom'),\n",
              " (5, 'Ġthe'),\n",
              " (5114, 'Ġ1980'),\n",
              " (29, 's'),\n",
              " (2, '</s>'),\n",
              " (1, '<pad>')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx5OrKh7xouk"
      },
      "source": [
        "#set([offsets for doc in train_encodings['offset_mapping'] for offsets in doc])\n",
        "collect = []\n",
        "for labels,offsets in zip(dataset['train_labels'], train_encodings['offset_mapping']):\n",
        "  collect.append((len(labels), len([offset for offset in offsets if offset[0] == 1 ])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX5mV1u90x1I"
      },
      "source": [
        "problems = [ (i,col) for (i, col) in enumerate(collect) if col[0] != col[1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5LGf-wv1vMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ffe8390-165f-45fe-f1c9-8608accd42d4"
      },
      "source": [
        "problems[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(10, (5, 6)),\n",
              " (16, (7, 8)),\n",
              " (17, (8, 9)),\n",
              " (19, (11, 12)),\n",
              " (20, (8, 9)),\n",
              " (26, (12, 14)),\n",
              " (29, (6, 7)),\n",
              " (30, (7, 8)),\n",
              " (34, (11, 12)),\n",
              " (40, (6, 7))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22L6SzDz2rkA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3813a410-e151-4314-cc41-6e8090a73f05"
      },
      "source": [
        "dataset['train_tokens'][10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'movie', 'is', 'references', 'zydrate']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRrwEld32h-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b380121e-3e4a-4bb9-ba48-fda1f7940487"
      },
      "source": [
        "[(val,tokenizer.convert_ids_to_tokens(val)) for val in train_encodings['input_ids'][10][0:15]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, '<s>'),\n",
              " (99, 'Ġwhat'),\n",
              " (1569, 'Ġmovie'),\n",
              " (16, 'Ġis'),\n",
              " (13115, 'Ġreferences'),\n",
              " (992, 'Ġz'),\n",
              " (9611, 'yd'),\n",
              " (7954, 'rate'),\n",
              " (2, '</s>'),\n",
              " (1, '<pad>'),\n",
              " (1, '<pad>'),\n",
              " (1, '<pad>'),\n",
              " (1, '<pad>'),\n",
              " (1, '<pad>'),\n",
              " (1, '<pad>')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arlb5PSb2Z-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae6e536-aaea-4398-8f6e-3686b2bf61a1"
      },
      "source": [
        "list(zip(train_encodings['input_ids'][10][0:15], train_encodings['attention_mask'][10][0:15], train_encodings['offset_mapping'][10][0:15]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1, (0, 0)),\n",
              " (99, 1, (1, 4)),\n",
              " (1569, 1, (1, 5)),\n",
              " (16, 1, (1, 2)),\n",
              " (13115, 1, (1, 10)),\n",
              " (992, 1, (1, 1)),\n",
              " (9611, 1, (1, 3)),\n",
              " (7954, 1, (3, 7)),\n",
              " (2, 1, (0, 0)),\n",
              " (1, 0, (0, 0)),\n",
              " (1, 0, (0, 0)),\n",
              " (1, 0, (0, 0)),\n",
              " (1, 0, (0, 0)),\n",
              " (1, 0, (0, 0)),\n",
              " (1, 0, (0, 0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKj1gmBi5pVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654fbfd9-5a13-4567-de52-c69044d03b46"
      },
      "source": [
        "tokenizer.convert_ids_to_tokens(train_encodings['input_ids'][10][0:15])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " 'Ġwhat',\n",
              " 'Ġmovie',\n",
              " 'Ġis',\n",
              " 'Ġreferences',\n",
              " 'Ġz',\n",
              " 'yd',\n",
              " 'rate',\n",
              " '</s>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khGuyFgJ5CQz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f33440-3a59-4de6-e31a-32bb41c2eb20"
      },
      "source": [
        "for i, token in enumerate(tokenizer.convert_ids_to_tokens(train_encodings['input_ids'][10][0:15])):\n",
        "  if ('Ġ' not in token) and ('<' not in token):\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lFHc0WjZBgu"
      },
      "source": [
        "### Adjust Labels for Vocab Offset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue6UQW-OZBgu"
      },
      "source": [
        " \n",
        "\n",
        "Based on https://datascience.stackexchange.com/questions/69640/what-should-be-the-labels-for-subword-tokens-in-bert-for-ner-task we will not drag the label to the new subword feature because that would introduce more instances of that class and change the number of support instances thus making the models difficult to compare. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMS4tTYbZBgv"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def adjust_labels_for_offset(original_labels, label_dictionary, encodings):\n",
        "\n",
        "    # convert to the numeric encoding of the label\n",
        "    labels = [[label_dictionary[label] for label in doc] for doc in original_labels]\n",
        "\n",
        "    encoded_labels = []\n",
        "    for doc_labels, doc_ids in zip(labels, encodings.input_ids):\n",
        "\n",
        "        # create an empty array of -100\n",
        "        doc_enc_labels = np.ones(len(doc_ids),dtype=int) * -100\n",
        "        arr_tokens = tokenizer.convert_ids_to_tokens(doc_ids)\n",
        "        labeled_tokens = [i for (i,token) in enumerate(arr_tokens) if ('Ġ' in token)]\n",
        "\n",
        "        # set labels to tokens who are \"primary\" tokens\n",
        "        doc_enc_labels[ labeled_tokens ] = doc_labels\n",
        "        encoded_labels.append(doc_enc_labels.tolist())\n",
        "\n",
        "    return encoded_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V11jF6XIZBg0"
      },
      "source": [
        "train_labels = adjust_labels_for_offset(dataset['train_labels'], \n",
        "                                        label_encoding, \n",
        "                                        train_encodings)\n",
        "\n",
        "test_labels = adjust_labels_for_offset(dataset['test_labels'],\n",
        "                                      label_encoding, \n",
        "                                      test_encodings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-kfOdqnZBg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ff85e5-175e-4407-8674-82c6cb740286"
      },
      "source": [
        "id_to_label = {id: label for (label,id) in label_encoding.items()}\n",
        "id_to_label[-100] = 'X'\n",
        "\n",
        "#print( tokenizer.convert_ids_to_tokens(encoding_example) )\n",
        "#print([id_to_label[id] for id in train_labels[0][0:9]])\n",
        "list(zip( tokenizer.convert_ids_to_tokens(train_encodings['input_ids'][0][0:15]), [id_to_label[id] for id in train_labels[0][0:15]], train_labels[0][0:15] )) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<s>', 'X', -100),\n",
              " ('Ġwhat', 'O', 21),\n",
              " ('Ġmovies', 'O', 21),\n",
              " ('Ġstar', 'O', 21),\n",
              " ('Ġbru', 'B-ACTOR', 13),\n",
              " ('ce', 'X', -100),\n",
              " ('Ġwill', 'I-ACTOR', 6),\n",
              " ('is', 'X', -100),\n",
              " ('</s>', 'X', -100),\n",
              " ('<pad>', 'X', -100),\n",
              " ('<pad>', 'X', -100),\n",
              " ('<pad>', 'X', -100),\n",
              " ('<pad>', 'X', -100),\n",
              " ('<pad>', 'X', -100),\n",
              " ('<pad>', 'X', -100)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUyVVipQZBg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf002ed-c172-4770-c1cd-5755a672d89b"
      },
      "source": [
        "np.unique(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-100,    0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
              "         10,   11,   12,   13,   14,   15,   16,   17,   18,   19,   20,\n",
              "         21,   22,   23,   24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4DYxki9ZBg9"
      },
      "source": [
        "### Prepare Pytorch Datasets\n",
        "\n",
        "https://huggingface.co/transformers/custom_datasets.html#ft-trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDFckRkEZBg-"
      },
      "source": [
        "import torch\n",
        "\n",
        "# pytorch is expecting a certain type of dataset \n",
        "\n",
        "class pt_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# remove the offset_mapping\n",
        "train_encodings.pop(\"offset_mapping\") \n",
        "test_encodings.pop(\"offset_mapping\")\n",
        "\n",
        "train_dataset = pt_dataset(train_encodings, train_labels)\n",
        "test_dataset = pt_dataset(test_encodings, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Lj8VcCvZBhB"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrSEhsu1ZBhB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "755f879722a442d1b73ad3e090114cca",
            "2eab4c0377754dbab90762729b1fb422",
            "d92527e8f9454455a7110307ab3e747d",
            "4cfc099451284c44a357bd5bd7aa4c9e",
            "2359cb61d5e2464aa3254f89f7e2f27b",
            "d3954fbcb10e44cbb28ef3635dbc9bbb",
            "1e08db1198d5472db61868f844c6c23d",
            "249f7b203e91495999cd80a0c06bfea2",
            "fb7c60d0eb164ef5a794462534d13074",
            "2a566bb724f1463a93402e778e040720",
            "d8184c11ab6d4652a346e383447b1ea0",
            "ce0c20dc37fa4cdcbb1f22fb3d3c30d9",
            "3670e0c83a2241eaa7dff489cffd5d5f",
            "95a3d10f094b4d21a0962f587cd5910f",
            "aab406c2738d41a5ae67b3a1a8783657",
            "ee5927d519e64597b0a6dcd148944c0d"
          ]
        },
        "outputId": "fa895bd9-34be-49e0-a16b-e3f3a89a1107"
      },
      "source": [
        "from transformers import RobertaForTokenClassification\n",
        "\n",
        "# load the pretrained model from huggingface\n",
        "model = RobertaForTokenClassification.from_pretrained('roberta-large', num_labels=len(uniq_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "755f879722a442d1b73ad3e090114cca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=482.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb7c60d0eb164ef5a794462534d13074",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1425941629.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTcaQIehZBhE"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# boiler plate code from huggingface to launch a trainer instance\n",
        "# sets directories and baseline configuration for batch sizes and weight decay\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = model_dir +  'mitmovie_pt_roberta_lg/results',          # output directory\n",
        "    overwrite_output_dir = True,\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir = model_dir +  'mitmovie_pt_roberta_lg/logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset = train_dataset,         # training dataset\n",
        "    eval_dataset = test_dataset             # evaluation dataset\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp7CY6pvZBhJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3c3accd5-d46d-43fd-80ff-d1dbea396af0"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla V100-SXM2-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNubi-1eZBhQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e819fcd9-b534-49cf-de8c-3210a7c88e31"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "print('Time to train:', datetime.now() - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='1833' max='1833' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1833/1833 09:47, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.443513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.305709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.939076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.147003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.741473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.452310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.234856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.008473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.865648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.706747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.530757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.587119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.496629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.408873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.321822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.426701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.365157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.361789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.337335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.287379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.386423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.304320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.390831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.284314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.445367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.251599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.295763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.320932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.295392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.374197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.372134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.324548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.287006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.297571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.215973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.293469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.262491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.319980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.390878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.276282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.263254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.226974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.325290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.225284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.302734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.252423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.265704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.236462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.324796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.313025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.239883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.322192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.334442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.237607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.265604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.292810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.207578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.284332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.309561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.273792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.319037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.309198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.210947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.312823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.265436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.218729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.213416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.307455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.229987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.293542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.242484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.205521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.205276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.235681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.236972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.195209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.294705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.346201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.235391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.196487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.216019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.168784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.252075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.229056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.212939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.246799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.277731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.185873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.180920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.257098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.315601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.149954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.181461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.199158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.186176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.269684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.206879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.186917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.218338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.164554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.225424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.202994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.202441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.184235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.203131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.199573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.157321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.304095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.243698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.268600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.214536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.165942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.238147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.283060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.170102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.178543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.191547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.211530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.186008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.237997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.178250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.248383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.154764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.184152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.171692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.146811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>0.147049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.133981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.181979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.180859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>0.178784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.143469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>0.143039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.144693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.155496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>0.109381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>0.145227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>0.154181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>0.134833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.230707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>0.176984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>0.193695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>0.170337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>0.161731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.162018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>0.192554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1470</td>\n",
              "      <td>0.087207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>0.132092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1490</td>\n",
              "      <td>0.126239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.192395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1510</td>\n",
              "      <td>0.150836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>0.224579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1530</td>\n",
              "      <td>0.162177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>0.154785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.146741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>0.158179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1570</td>\n",
              "      <td>0.140668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>0.142877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1590</td>\n",
              "      <td>0.117633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.116754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>0.189545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>0.161078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1630</td>\n",
              "      <td>0.123688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>0.123151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.131854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>0.160516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1670</td>\n",
              "      <td>0.096326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>0.112762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1690</td>\n",
              "      <td>0.130103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.130731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1710</td>\n",
              "      <td>0.176428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1720</td>\n",
              "      <td>0.169324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1730</td>\n",
              "      <td>0.143005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1740</td>\n",
              "      <td>0.115106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.173163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1760</td>\n",
              "      <td>0.105054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1770</td>\n",
              "      <td>0.167249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1780</td>\n",
              "      <td>0.121497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1790</td>\n",
              "      <td>0.142786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.125568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1810</td>\n",
              "      <td>0.168207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>0.117828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1830</td>\n",
              "      <td>0.177490</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time to train: 0:09:47.493211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1evbz_dZBhS"
      },
      "source": [
        "trainer.save_model(model_dir + 'mitmovie_pt_roberta_lg/model')\n",
        "#model.save_pretrained(model_dir + 'mitmovie_pt_roberta_lg/model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwRnx0uAZBhW"
      },
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0WIuVvYE2rp"
      },
      "source": [
        "model = None\n",
        "trainer = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOWVPl50ZBhW"
      },
      "source": [
        "# retreive the saved model \n",
        "model = RobertaForTokenClassification.from_pretrained(model_dir + 'mitmovie_pt_roberta_lg/model', num_labels=len(uniq_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAe9c-GByIZJ"
      },
      "source": [
        "model.eval();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcSDIKDAZBhb"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset = train_dataset,         # training dataset\n",
        "    eval_dataset = test_dataset             # evaluation dataset\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1hSyWahZBhe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c0993c61-bfb2-4493-b7c7-87d4acaf0326"
      },
      "source": [
        "# last layer output/activation has the shape of (batch_size, seq_len,num_of_labels)\n",
        "output, label_ids, metrics = trainer.predict(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [39/39 00:05]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBfTWKSgZBhi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "967efef0-127d-42a3-e9da-5b3172b80329"
      },
      "source": [
        "metrics\n",
        "# 'eval_loss': 0.2402782440185547"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.24496054649353027}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK4MNIRKZBhl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957557aa-e0f8-4e4d-99d6-ad9ab161a160"
      },
      "source": [
        "# convert output which is logits to index of max logit\n",
        "preds = np.argmax(output, axis=2)\n",
        "preds.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2443, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HylnQU9SZBho"
      },
      "source": [
        "# https://medium.com/analytics-vidhya/named-entity-recognition-for-turkish-with-bert-f8ec04a31b0\n",
        "# this function formats the predictions by removing the padding\n",
        "# so that we can line it up directly with original data\n",
        "\n",
        "batch_size, seq_len = preds.shape\n",
        "\n",
        "# list of token-level predictions shape = (batch_size, seq_len)\n",
        "preds_list = [[] for _ in range(batch_size)]\n",
        "for i in range(batch_size):\n",
        "  for j in range(seq_len):\n",
        "    # ignore pad_tokens\n",
        "    if label_ids[i, j] != -100: # torch.nn.CrossEntropyLoss().ignore_index:\n",
        "      preds_list[i].append(id_to_label[preds[i][j]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvdLgbTGZBhr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9cd99f5-3d20-4b72-e71a-51fba5f032bd"
      },
      "source": [
        "# you can see the number of predicted values and the actual values for a \n",
        "# given doc is the same, implying that the predictions line up\n",
        "# to the actuals because we set labels to -100 for [cls], [sep], and ## subwords\n",
        "len(preds_list[6]), len(dataset['test_tokens'][6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atMzaZ-nZBhu"
      },
      "source": [
        "preds_stretched = [label for doc in preds_list for label in doc]\n",
        "trues_stretched = [label for doc in dataset['test_labels'] for label in doc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwPMYcUFZBhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ca88c6-085c-4014-fa40-784a313b2c34"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "f = open(model_dir + 'mitmovie_pt_roberta_lg/model'  + '/class_report_test.txt', 'w') \n",
        "\n",
        "class_report = classification_report(trues_stretched, preds_stretched)\n",
        "print(class_report, file=f ) \n",
        "\n",
        "f.close()\n",
        "\n",
        "print(class_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "          B-ACTOR       0.93      0.94      0.93       812\n",
            "      B-CHARACTER       0.70      0.77      0.73        90\n",
            "       B-DIRECTOR       0.92      0.88      0.90       456\n",
            "          B-GENRE       0.94      0.97      0.95      1117\n",
            "           B-PLOT       0.80      0.77      0.78       491\n",
            "         B-RATING       0.98      0.97      0.97       500\n",
            "B-RATINGS_AVERAGE       0.94      0.92      0.93       451\n",
            "         B-REVIEW       0.36      0.23      0.28        56\n",
            "           B-SONG       0.73      0.74      0.73        54\n",
            "          B-TITLE       0.90      0.90      0.90       562\n",
            "        B-TRAILER       0.82      0.90      0.86        30\n",
            "           B-YEAR       0.96      0.95      0.96       720\n",
            "          I-ACTOR       0.93      0.93      0.93       862\n",
            "      I-CHARACTER       0.67      0.60      0.63        75\n",
            "       I-DIRECTOR       0.91      0.88      0.89       496\n",
            "          I-GENRE       0.89      0.74      0.81       222\n",
            "           I-PLOT       0.79      0.69      0.74       496\n",
            "         I-RATING       0.96      0.89      0.93       226\n",
            "I-RATINGS_AVERAGE       0.88      0.93      0.90       403\n",
            "         I-REVIEW       0.50      0.11      0.18        45\n",
            "           I-SONG       0.89      0.79      0.84       119\n",
            "          I-TITLE       0.91      0.93      0.92       856\n",
            "        I-TRAILER       0.00      0.00      0.00         8\n",
            "           I-YEAR       0.97      0.98      0.97       610\n",
            "                O       0.97      0.98      0.97     14929\n",
            "\n",
            "         accuracy                           0.95     24686\n",
            "        macro avg       0.81      0.78      0.79     24686\n",
            "     weighted avg       0.94      0.95      0.94     24686\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHSbhQgkZBhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd2be5c-d77f-428c-8684-b77985708728"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUF0SrO5ZBh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820ec62f-c411-47ac-c714-40f089f986f3"
      },
      "source": [
        "from seqeval.metrics import classification_report as classification_report_seqeval\n",
        "\n",
        "f = open(model_dir + 'mitmovie_pt_roberta_lg/model'  + '/seq_class_report_test.txt', 'w') \n",
        "\n",
        "seq_class_report = classification_report_seqeval(dataset['test_labels'], preds_list)\n",
        "print(seq_class_report, file=f ) \n",
        "\n",
        "f.close() \n",
        "print(seq_class_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          ACTOR       0.91      0.93      0.92       812\n",
            "      CHARACTER       0.63      0.71      0.67        90\n",
            "       DIRECTOR       0.91      0.88      0.89       456\n",
            "          GENRE       0.91      0.94      0.93      1117\n",
            "           PLOT       0.73      0.75      0.74       491\n",
            "         RATING       0.94      0.93      0.93       500\n",
            "RATINGS_AVERAGE       0.89      0.89      0.89       451\n",
            "         REVIEW       0.30      0.20      0.24        56\n",
            "           SONG       0.49      0.57      0.53        54\n",
            "          TITLE       0.87      0.88      0.88       562\n",
            "        TRAILER       0.82      0.90      0.86        30\n",
            "           YEAR       0.96      0.95      0.95       720\n",
            "\n",
            "      micro avg       0.88      0.89      0.89      5339\n",
            "      macro avg       0.78      0.79      0.79      5339\n",
            "   weighted avg       0.88      0.89      0.89      5339\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3acBRKKlZBh5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r540D8sCxZGv"
      },
      "source": [
        "## XLNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPi5QX8rNuDg"
      },
      "source": [
        "model_version = 'xlnet-base-cased'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlz_WVG60sOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45eb9428-f8ee-4c0e-8696-ecdb038605d4"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO28BkQl00UY"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ads7LA6p2b5E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dfbb5828-c36e-4cb5-f55a-32ca6d46cbd4"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKyORHtdOFX_"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NdB5Tlc0sOR"
      },
      "source": [
        "### Encode Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBozlvpu0sOR"
      },
      "source": [
        "# get the set of unique labels in the movie dataset\n",
        "uniq_labels = set([label for doc in dataset['train_labels'] for label in doc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Bcl6Sj0sOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88435bd-6eff-4872-c2d2-1275f0b5a59a"
      },
      "source": [
        "# assign a number to each label\n",
        "label_encoding = {label: id for id, label in enumerate(uniq_labels)}\n",
        "label_encoding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-ACTOR': 4,\n",
              " 'B-CHARACTER': 16,\n",
              " 'B-DIRECTOR': 0,\n",
              " 'B-GENRE': 24,\n",
              " 'B-PLOT': 1,\n",
              " 'B-RATING': 15,\n",
              " 'B-RATINGS_AVERAGE': 5,\n",
              " 'B-REVIEW': 2,\n",
              " 'B-SONG': 7,\n",
              " 'B-TITLE': 6,\n",
              " 'B-TRAILER': 14,\n",
              " 'B-YEAR': 21,\n",
              " 'I-ACTOR': 22,\n",
              " 'I-CHARACTER': 23,\n",
              " 'I-DIRECTOR': 20,\n",
              " 'I-GENRE': 13,\n",
              " 'I-PLOT': 17,\n",
              " 'I-RATING': 18,\n",
              " 'I-RATINGS_AVERAGE': 3,\n",
              " 'I-REVIEW': 8,\n",
              " 'I-SONG': 11,\n",
              " 'I-TITLE': 10,\n",
              " 'I-TRAILER': 19,\n",
              " 'I-YEAR': 12,\n",
              " 'O': 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5wxWsS60sOV"
      },
      "source": [
        "### Encode Texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBcdEpdK0sOW"
      },
      "source": [
        "To encode the texts, we have to use the same Tokenizer that xlnet was trained on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p1H06ao0sOW"
      },
      "source": [
        "from transformers import XLNetTokenizer\n",
        "\n",
        "tokenizer = XLNetTokenizer.from_pretrained(model_version, do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZwM4MwF0sOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d1e4bea-e93a-4fe8-8dd3-1358cd7198cb"
      },
      "source": [
        "print('There are %s words in this tokenizer object' % tokenizer.vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 32000 words in this tokenizer object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNnPyIGF6Acw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b79a1902-67f7-45c5-a79c-172fad5c2bf3"
      },
      "source": [
        "# join the tokenize before passing to tokenizer object\n",
        "\n",
        "print (\"Tokenize the first sentence:\")\n",
        "toked = tokenizer.encode_plus(' '.join(dataset['train_tokens'][0]))\n",
        "print(toked)\n",
        "print(tokenizer.convert_ids_to_tokens(toked['input_ids']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenize the first sentence:\n",
            "{'input_ids': [113, 3547, 1795, 17, 10997, 1138, 53, 590, 4, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "['▁what', '▁movies', '▁star', '▁', 'bru', 'ce', '▁will', 'is', '<sep>', '<cls>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4O85Xmj5MXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb95f4f6-db7c-4859-f380-2c5e98757351"
      },
      "source": [
        "#tokenizer.get_vocab()['oph']\n",
        "tokenizer.pad_token_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTv1oxcg6wNS"
      },
      "source": [
        "#from keras.preprocessing.sequence import pad_sequences\n",
        "# https://medium.com/swlh/using-xlnet-for-sentiment-classification-cfa948e65e85\n",
        "\n",
        "def make_xlnet_encodings(text, tokenizer, MAX_LEN):\n",
        "\n",
        "  input_ids, token_type_ids, attention_mask = [], [], []\n",
        "  for doc in text:\n",
        "  #   toked = tokenizer(' '.join(doc))\n",
        "  #   input_ids.append(toked['input_ids'])\n",
        "  #   #token_type_ids.append(toked['token_type_ids'])\n",
        "  #   #attention_mask.append(seq_mask)\n",
        "\n",
        "  # input_ids = pad_sequences(input_ids, \n",
        "  #                           maxlen = 80, \n",
        "  #                           dtype=\"long\", \n",
        "  #                           truncating=\"post\", \n",
        "  #                           padding=\"post\", \n",
        "  #                           value = tokenizer.pad_token_id #xlnet padding id is 5\n",
        "  #                           )\n",
        "\n",
        "  # attention_mask = []\n",
        "  # for seq in input_ids:\n",
        "  #   seq_mask = [float(i != 5) for i in seq]\n",
        "  #   attention_mask.append(seq_mask)\n",
        "\n",
        "    encoding = tokenizer.encode_plus(\n",
        "            ' '.join(doc),\n",
        "            add_special_tokens=True,\n",
        "            max_length = 65,\n",
        "            truncation = True,\n",
        "            return_token_type_ids=False,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True\n",
        "            )\n",
        "\n",
        "    input_ids.append(encoding['input_ids'])\n",
        "    attention_mask.append(encoding['attention_mask'])   \n",
        "\n",
        "  encodings = {'input_ids': input_ids, \n",
        "              #'token_type_ids': token_type_ids,\n",
        "              'attention_mask': attention_mask}\n",
        "  return encodings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF7ZXTUSxYHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ff35ab-f919-4d03-ecd5-9a4106f1560d"
      },
      "source": [
        "train_encodings = make_xlnet_encodings(dataset['train_tokens'], tokenizer, 50)\n",
        "test_encodings = make_xlnet_encodings(dataset['test_tokens'], tokenizer, 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03ErrOS7H91X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cfb7344-13a4-4a22-b9fb-8db87ed45d0b"
      },
      "source": [
        "train_encodings['input_ids'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 113,\n",
              " 3547,\n",
              " 1795,\n",
              " 17,\n",
              " 10997,\n",
              " 1138,\n",
              " 53,\n",
              " 590,\n",
              " 4,\n",
              " 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41BmpFdb0sOc"
      },
      "source": [
        "# variation of https://mccormickml.com/2019/09/19/XLNet-fine-tuning/\n",
        "# from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# def get_ids_masks(text, tokenizer, MAX_LEN):\n",
        "#   ''' this function will take a list-of-lists and a tokenizer\n",
        "#   and return input_ids and attention_masks\n",
        "#   '''\n",
        "\n",
        "#   # tokenize according to the tokenizer\n",
        "#   tokenized_text = [tokenizer.tokenize(' '.join(doc) ) for doc in text]\n",
        "\n",
        "#   # get ids\n",
        "#   input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_text]\n",
        "\n",
        "#   # pad input tokens\n",
        "#   input_ids = pad_sequences(input_ids, \n",
        "#                             maxlen=MAX_LEN, \n",
        "#                             dtype=\"long\", \n",
        "#                             truncating=\"post\", \n",
        "#                             padding=\"post\", \n",
        "#                             value = tokenizer.pad_token_id #xlnet padding id is 5\n",
        "#                             )\n",
        "\n",
        "#   # Create attention masks\n",
        "#   attention_masks = []\n",
        "#   # Create a mask of 1s for each token followed by 0s for padding\n",
        "#   for seq in input_ids:\n",
        "#     seq_mask = [float(i != 5) for i in seq]\n",
        "#     attention_masks.append(seq_mask)\n",
        "\n",
        "#   return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jROGnE9pSMez"
      },
      "source": [
        "# train_ids, train_masks = get_ids_masks(dataset['train_tokens'], tokenizer, 65)\n",
        "# test_ids, test_masks = get_ids_masks(dataset['test_tokens'], tokenizer, 65)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gevpGjUL0sOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "394c6b3f-3a5c-4de2-8f81-f1623e6378b8"
      },
      "source": [
        "# first document in dataset\n",
        "print( dataset['train_tokens'][1] )\n",
        "\n",
        "# check out new tokenization result as words\n",
        "print( tokenizer.convert_ids_to_tokens( train_encodings['input_ids'][1]) )\n",
        "\n",
        "# check out new tokenization result as ids\n",
        "print( [val for val in train_encodings['input_ids'][1]] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['show', 'me', 'films', 'with', 'drew', 'barrymore', 'from', 'the', '1980s']\n",
            "['<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '▁show', '▁me', '▁films', '▁with', '▁drew', '▁bar', 'ry', 'more', '▁from', '▁the', '▁1980', 's', '<sep>', '<cls>']\n",
            "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 351, 110, 2701, 33, 3767, 1808, 844, 3067, 40, 18, 1910, 23, 4, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9jOCfOM6Wrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cdfd54c-7b05-43bc-9f5d-6c925ed6e868"
      },
      "source": [
        "collect = []\n",
        "for labels,ids in zip(dataset['train_labels'], train_encodings['input_ids']):\n",
        "  tokens = tokenizer.convert_ids_to_tokens(ids)\n",
        "  collect.append((len(labels), len([token for token in tokens if '▁' in token])))\n",
        "\n",
        "len(collect)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9775"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqJ3UgjwBgWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe1b623-b7dd-4944-9758-37dac54cb2ac"
      },
      "source": [
        "[i for (i, col) in enumerate(collect) if col[0] != col[1]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQCRRjax0sOs"
      },
      "source": [
        "### Adjust Labels for Vocab Offset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGbWYEpn0sOs"
      },
      "source": [
        "\n",
        "\n",
        "Based on https://datascience.stackexchange.com/questions/69640/what-should-be-the-labels-for-subword-tokens-in-bert-for-ner-task we will not drag the label to the new subword feature because that would introduce more instances of that class and change the number of support instances thus making the models difficult to compare. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAqlDiv90sOs"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def adjust_labels_for_offset(original_labels, label_dictionary, input_ids):\n",
        "\n",
        "    # convert to the numeric encoding of the label\n",
        "    labels = [[label_dictionary[label] for label in doc] for doc in original_labels]\n",
        "\n",
        "    encoded_labels = []\n",
        "    for doc_labels, doc_ids in zip(labels, input_ids):\n",
        "\n",
        "        # create an empty array of -100\n",
        "        doc_enc_labels = np.ones(len(doc_ids),dtype=int) * -100\n",
        "        arr_tokens = tokenizer.convert_ids_to_tokens(doc_ids)\n",
        "        labeled_tokens = [i for (i,token) in enumerate(arr_tokens) if '▁' in token]\n",
        "\n",
        "        # set labels to tokens who are \"primary\" tokens\n",
        "        doc_enc_labels[ labeled_tokens ] = doc_labels\n",
        "        encoded_labels.append(doc_enc_labels.tolist())\n",
        "\n",
        "    return encoded_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkoZ4_SD0sOt"
      },
      "source": [
        "train_labels = adjust_labels_for_offset(dataset['train_labels'], \n",
        "                                        label_encoding, \n",
        "                                        train_encodings['input_ids'])\n",
        "\n",
        "test_labels = adjust_labels_for_offset(dataset['test_labels'],\n",
        "                                      label_encoding, \n",
        "                                      test_encodings['input_ids'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVo2EDqq0sOv"
      },
      "source": [
        "id_to_label = {id: label for (label,id) in label_encoding.items()}\n",
        "id_to_label[-100] = 'X'\n",
        "\n",
        "#print( tokenizer.convert_ids_to_tokens(encoding_example) )\n",
        "#print([id_to_label[id] for id in train_labels[0][0:9]])\n",
        "list(zip( tokenizer.convert_ids_to_tokens(train_encodings['input_ids'][0]), \n",
        "         [id_to_label[id] for id in train_labels[0]], \n",
        "         train_labels[0],\n",
        "         train_encodings['attention_mask'][0])) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gUr4ce0sOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dd14431-1a19-4bdf-a2e6-7612e3cbab88"
      },
      "source": [
        "np.unique(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-100,    0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
              "         10,   11,   12,   13,   14,   15,   16,   17,   18,   19,   20,\n",
              "         21,   22,   23,   24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SUbeYYY0sOy"
      },
      "source": [
        "### Prepare Pytorch Datasets\n",
        "\n",
        "https://huggingface.co/transformers/custom_datasets.html#ft-trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRFdD-4i0sOz"
      },
      "source": [
        "import torch\n",
        "\n",
        "# pytorch is expecting a certain type of dataset \n",
        "\n",
        "class pt_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# remove the offset_mapping\n",
        "#train_encodings.pop(\"offset_mapping\") \n",
        "#test_encodings.pop(\"offset_mapping\")\n",
        "\n",
        "train_dataset = pt_dataset(train_encodings, train_labels)\n",
        "test_dataset = pt_dataset(test_encodings, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PveogQ39L38E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11bc88c6-a98b-4d4e-e37f-ec13ba608279"
      },
      "source": [
        "len(test_dataset.encodings['input_ids']), len(test_dataset.labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2443, 2443)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPg9Lfux0sO0"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fljt9Zk30sO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf0d84af-f0c3-443a-91d5-89d3c8dfad05"
      },
      "source": [
        "from transformers import XLNetForTokenClassification\n",
        "\n",
        "# load the pretrained model from huggingface\n",
        "#model = DistilBertForTokenClassification.from_pretrained('distilbert-base-cased', num_labels=len(uniq_labels))\n",
        "model = XLNetForTokenClassification.from_pretrained(model_version, num_labels=len(uniq_labels), mem_len=1024)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `mem_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
            "  FutureWarning,\n",
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForTokenClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
            "- This IS expected if you are initializing XLNetForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing XLNetForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLNetForTokenClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX3znyM2N62W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7354c0b6-d90a-4cde-f124-ce654e25c1cc"
      },
      "source": [
        "folder_name = 'mitmovie_' + model_version.replace('-', '_')\n",
        "folder_name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'mitmovie_xlnet_base_cased'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWjmMNIO0sO2"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# boiler plate code from huggingface to launch a trainer instance\n",
        "# sets directories and baseline configuration for batch sizes and weight decay\n",
        "trainer = None\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = model_dir +   folder_name + '/results',          # output directory\n",
        "    overwrite_output_dir = True,\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir = model_dir +  folder_name + '/logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset = train_dataset,         # training dataset\n",
        "    eval_dataset = test_dataset             # evaluation dataset\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Teh4vM7LhF1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ec9c16b3-cd53-4f9e-9853-643faf298e14"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "print('Time to train:', datetime.now() - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='1833' max='1833' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1833/1833 05:09, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>6.925253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>4.946571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.682056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.303178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.120535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.936699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.825957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.793875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.766829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.650247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.539630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.495978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.383340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.195923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.011395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.036307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.915076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.856952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.837448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.736972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.779285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.634680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.718802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.563724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.712296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.457520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.566147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.563950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.390872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.607755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.508255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.472147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.444516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.409064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.392621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.422269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.365213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.433459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.486456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.377374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.337549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.360910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.381473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.278973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.328970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.286768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.306293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.281079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.382483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.333716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.302338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.332556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.375995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.241571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.325024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.359308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.242767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.311652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.341180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.317657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.306598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.326495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.235754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.303802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.243823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.221954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.253076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.331842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.261066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.345953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.267542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.219849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.216986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.250159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.263721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.232904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.304541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.314288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.217609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.236505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.220856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.171094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.282758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.240692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.220935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.266119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.236993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.192255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.197827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.277643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.323145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.175073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.228320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.265063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.201843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.270361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.214166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.190192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.207843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.199805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.213910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.210260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.210248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.210907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.243774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.185754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.174835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.303851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.257916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.272595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.235394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.193536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.255750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.297601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.186493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.177100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.201691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.207874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.195612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.232513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.189893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.278119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.178137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.159467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.183539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.182440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>0.155151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.114771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.203265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.198743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>0.201239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.140271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>0.153217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.162140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.160345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>0.135980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>0.144745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>0.175317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>0.136206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.197162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>0.177100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>0.170117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>0.193060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>0.145258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.162921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>0.225836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1470</td>\n",
              "      <td>0.107837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>0.117310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1490</td>\n",
              "      <td>0.116333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.173718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1510</td>\n",
              "      <td>0.172455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>0.202570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1530</td>\n",
              "      <td>0.161218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>0.146954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.140686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>0.177142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1570</td>\n",
              "      <td>0.162994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>0.163519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1590</td>\n",
              "      <td>0.117139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.132269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>0.193903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>0.159167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1630</td>\n",
              "      <td>0.135858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>0.123688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.131189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>0.161438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1670</td>\n",
              "      <td>0.104065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>0.110406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1690</td>\n",
              "      <td>0.131207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.124011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1710</td>\n",
              "      <td>0.179425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1720</td>\n",
              "      <td>0.177484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1730</td>\n",
              "      <td>0.142511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1740</td>\n",
              "      <td>0.131122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.178796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1760</td>\n",
              "      <td>0.116766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1770</td>\n",
              "      <td>0.161218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1780</td>\n",
              "      <td>0.137720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1790</td>\n",
              "      <td>0.133527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.133807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1810</td>\n",
              "      <td>0.157147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>0.127411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1830</td>\n",
              "      <td>0.175824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time to train: 0:05:10.212920\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbHOK31wMXdN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "cd92ccee-6067-45c5-8931-c44210de782e"
      },
      "source": [
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='38' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [38/39 00:09 < 00:00, 3.89 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-f245b31d31e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0meval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_eval_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only)\u001b[0m\n\u001b[1;32m   1351\u001b[0m                 \u001b[0mlosses_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlosses_host\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m                 \u001b[0mpreds_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreds_host\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m                 \u001b[0mlabels_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels_host\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, dim)\u001b[0m\n\u001b[1;32m     45\u001b[0m     ), f\"Expected `tensors` and `new_tensors` to have the same type but found {type(tensors)} and {type(new_tensors)}.\"\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m     ), f\"Expected `tensors` and `new_tensors` to have the same type but found {type(tensors)} and {type(new_tensors)}.\"\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, dim)\u001b[0m\n\u001b[1;32m     45\u001b[0m     ), f\"Expected `tensors` and `new_tensors` to have the same type but found {type(tensors)} and {type(new_tensors)}.\"\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m     ), f\"Expected `tensors` and `new_tensors` to have the same type but found {type(tensors)} and {type(new_tensors)}.\"\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, dim)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Got 11 and 64 (The offending index is 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjDpLvpf0sO4"
      },
      "source": [
        "trainer.save_model(model_dir + folder_name + '/model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly3TkL5QKlmh"
      },
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdmpgfG6Klmj"
      },
      "source": [
        "from transformers import XLNetForTokenClassification\n",
        "\n",
        "# retreive the saved model \n",
        "model = XLNetForTokenClassification.from_pretrained(model_dir + folder_name + '/model', num_labels=len(uniq_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjHU6cVtKlmm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "247595c9-11a2-42bc-f5eb-35b393df67ad"
      },
      "source": [
        "# last layer output/activation has the shape of (batch_size, seq_len,num_of_labels)\n",
        "output, label_ids, metrics = trainer.predict(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='152' max='153' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [152/153 00:22 < 00:00, 6.57 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-6da0bc71eda8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# last layer output/activation has the shape of (batch_size, seq_len,num_of_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_test_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m     def prediction_loop(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only)\u001b[0m\n\u001b[1;32m   1351\u001b[0m                 \u001b[0mlosses_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlosses_host\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m                 \u001b[0mpreds_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreds_host\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m                 \u001b[0mlabels_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels_host\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, dim)\u001b[0m\n\u001b[1;32m     45\u001b[0m     ), f\"Expected `tensors` and `new_tensors` to have the same type but found {type(tensors)} and {type(new_tensors)}.\"\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m     ), f\"Expected `tensors` and `new_tensors` to have the same type but found {type(tensors)} and {type(new_tensors)}.\"\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, dim)\u001b[0m\n\u001b[1;32m     45\u001b[0m     ), f\"Expected `tensors` and `new_tensors` to have the same type but found {type(tensors)} and {type(new_tensors)}.\"\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m     ), f\"Expected `tensors` and `new_tensors` to have the same type but found {type(tensors)} and {type(new_tensors)}.\"\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, dim)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Got 11 and 16 (The offending index is 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-muuOeHKlmo"
      },
      "source": [
        "metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYgSs7HJKlmq"
      },
      "source": [
        "# convert output which is logits to index of max logit\n",
        "preds = np.argmax(output, axis=2)\n",
        "preds.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbl9oNFRKlmr"
      },
      "source": [
        "# https://medium.com/analytics-vidhya/named-entity-recognition-for-turkish-with-bert-f8ec04a31b0\n",
        "# this function formats the predictions by removing the padding\n",
        "# so that we can line it up directly with original data\n",
        "\n",
        "batch_size, seq_len = preds.shape\n",
        "\n",
        "# list of token-level predictions shape = (batch_size, seq_len)\n",
        "preds_list = [[] for _ in range(batch_size)]\n",
        "for i in range(batch_size):\n",
        "  for j in range(seq_len):\n",
        "    # ignore pad_tokens\n",
        "    if label_ids[i, j] != -100: # torch.nn.CrossEntropyLoss().ignore_index:\n",
        "      preds_list[i].append(id_to_label[preds[i][j]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n318DQDHKlmu"
      },
      "source": [
        "# you can see the number of predicted values and the actual values for a \n",
        "# given doc is the same, implying that the predictions line up\n",
        "# to the actuals because we set labels to -100 for [cls], [sep], and ## subwords\n",
        "len(preds_list[6]), len(dataset['test_tokens'][6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voCHzNdmKlmv"
      },
      "source": [
        "preds_stretched = [label for doc in preds_list for label in doc]\n",
        "trues_stretched = [label for doc in dataset['test_labels'] for label in doc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFIV0odwKlmw"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "f = open(model_dir + folder_name + '/model'  + '/class_report_test.txt', 'w') \n",
        "\n",
        "class_report = classification_report(trues_stretched, preds_stretched)\n",
        "print(class_report, file=f ) \n",
        "\n",
        "f.close()\n",
        "\n",
        "print(class_report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fidIw1cJKlmy"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GYoFmBkKlmz"
      },
      "source": [
        "from seqeval.metrics import classification_report as classification_report_seqeval\n",
        "\n",
        "f = open(model_dir + folder_name + '/model'  + '/seq_class_report_test.txt', 'w') \n",
        "\n",
        "seq_class_report = classification_report_seqeval(dataset['test_labels'], preds_list)\n",
        "print(seq_class_report, file=f ) \n",
        "\n",
        "f.close() \n",
        "print(seq_class_report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAhzX_10Klm1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsRaKLrZQ7wP"
      },
      "source": [
        "## Unused code\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46FjpW2CQ_Hy"
      },
      "source": [
        "Don't use the TF versions below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R42MxeUUxvWS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "24bfc535-d545-409b-800b-561e3e9385a0"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# remove the offset_mapping\n",
        "train_encodings.pop(\"offset_mapping\") \n",
        "test_encodings.pop(\"offset_mapping\")\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    train_labels\n",
        "))\n",
        "\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    test_labels\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-f623610ca65c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# remove the offset_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_encodings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"offset_mapping\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_encodings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"offset_mapping\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/_collections_abc.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    793\u001b[0m         '''\n\u001b[1;32m    794\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__marker\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \"\"\"\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encodings\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'offset_mapping'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEBB7Z3oyEmz"
      },
      "source": [
        "from transformers import TFDistilBertForTokenClassification, TFTrainer, TFTrainingArguments\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKKncfxqyZKF"
      },
      "source": [
        "# retrieve the distilbert model\n",
        "model = TFDistilBertForTokenClassification.from_pretrained('distilbert-base-cased', \n",
        "                                                           num_labels=len(uniq_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOIr1KtzDKE1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVENb8xF_u-7"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "model.compile(optimizer=optimizer, loss=model.compute_loss) #sparsecategorical crossentropy is default\n",
        "history = model.fit(train_dataset.shuffle(1000).batch(16), epochs=3, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Oz4oMqI6q1R"
      },
      "source": [
        "model.save_pretrained(model_dir + \"mitmovie_distilbert\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XSeE3iT6I4Q"
      },
      "source": [
        "#model.from_pretrained(model_dir + \"mitmovie_distilbert\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t5Mb9I7AFF3"
      },
      "source": [
        "logits = model.predict(test_dataset)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzvlBycX9XdO"
      },
      "source": [
        "logits.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbXe0pFf-MjT"
      },
      "source": [
        "tf.nn.softmax(logits[0], axis= -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFUPR4XU7Okc"
      },
      "source": [
        "preds = []\n",
        "for row in range(logits.shape[0]):\n",
        "  pred = np.argmax(tf.nn.softmax(logits[row], axis = -1))\n",
        "  preds.append(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cshk539t77tm"
      },
      "source": [
        "pred_decode = [id_to_label[pred] for pred in preds]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_YEm0wZ7JvU"
      },
      "source": [
        "trues = [label for doc in test_labels for label in doc]\n",
        "len(trues)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3D22XE5BRKl"
      },
      "source": [
        "for true, pred in zip(trues[0:100], preds[0:100]):\n",
        "  if true != -100:\n",
        "    print(id_to_label[true], '  ', id_to_label[pred])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL7TrFKt-BTB"
      },
      "source": [
        "i = 35\n",
        "p = model.predict(np.array(X_te[i:i+batch_size]))[0]\n",
        "p = np.argmax(p, axis=-1)\n",
        "print(\"{:15} {:5}: ({})\".format(\"Word\", \"Pred\", \"True\"))\n",
        "print(\"=\"*30)\n",
        "for w, true, pred in zip(X_te[i], y_te[i], p):\n",
        "    if w != \"__PAD__\":\n",
        "        print(\"{:15}:{:5} ({})\".format(w, tags[pred], tags[true]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhnDH5H786ag"
      },
      "source": [
        "id_to_label[20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7CLLQUI9MXa"
      },
      "source": [
        "test_true = [label for doc in test_labels for label in doc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBv439QW_dbi"
      },
      "source": [
        "[id_to_label[val] for val in test_true[0:10]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrcpYuI09CfD"
      },
      "source": [
        "dataset['test_labels'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po9BbL2f7Fyr"
      },
      "source": [
        "pred_vec = tf.nn.softmax(logits, axis=1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olkAMzGP7Yjb"
      },
      "source": [
        "pred_vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJZfCQJ2GimF"
      },
      "source": [
        "len([val for val in test_encodings['input_ids']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQbXA70-GWcM"
      },
      "source": [
        "len( pred_vec[0] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mPTQH13Fa73"
      },
      "source": [
        "preds = np.argmax(pred_vec, axis=2)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1CUZ6_hDFBM"
      },
      "source": [
        "preds = np.argmax(output, axis=2)\n",
        "batch_size, seq_len = preds.shape\n",
        "\n",
        "# list of token-level predictions shape = (batch_size, seq_len)\n",
        "preds_list = [[] for _ in range(batch_size)]\n",
        "for i in range(batch_size):\n",
        "  for j in range(seq_len):\n",
        "    # ignore pad_tokens\n",
        "    if label_ids[i, j] != nn.CrossEntropyLoss().ignore_index:\n",
        "      preds_list[i].append(label_map[preds[i][j]])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}